{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4706184",
   "metadata": {},
   "source": [
    "# TP4 - Data Mining : Unsupervised Learning Alogrithmes GUI \n",
    "\n",
    "**Spécialité:** 4th year Software Engineering (ING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0f669",
   "metadata": {},
   "source": [
    "#### to compile , execute run all and the GUI will appear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0dfa6",
   "metadata": {},
   "source": [
    "### 1 - Création de l'interface graphique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d054e6c",
   "metadata": {},
   "source": [
    "### 1 -a  navbar menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "398b041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "# navbar buttons\n",
    "menuButtons = [\"Upload Data Set\", \"Pretraitement\", \"Clustering Metrics\",\n",
    "               \"Algorithms\", \"Visualization\",\"Comparaison\"]\n",
    "\n",
    "currentStep = 0\n",
    "\n",
    "window = tk.Tk()\n",
    "window.resizable(False, False)\n",
    "window.title(\"Unsupervised Learning GUI\")\n",
    "window.geometry(\"900x500\")\n",
    "\n",
    "# navbar frame\n",
    "navbarMenu = tk.Frame(window, bg=\"#7b9fc2\", height=120)\n",
    "navbarMenu.pack(fill=tk.X, side=tk.TOP)\n",
    "\n",
    "horizontalNavbarMenu = tk.Frame(navbarMenu, bg=\"#7b9fc2\")\n",
    "horizontalNavbarMenu.pack(expand=True)\n",
    "\n",
    "for button in menuButtons:\n",
    "    button = tk.Button(horizontalNavbarMenu, text=button, bg=\"#d9e4f5\", height=1, fg=\"#24367E\", font=(\n",
    "        \"Arial\", 13), bd=0, relief='ridge', highlightthickness=5, highlightbackground=\"#7b9fc2\")\n",
    "    # pack method to arrange buttons horizontally and centered\n",
    "    button.pack(side=tk.LEFT, padx=10, pady=15)\n",
    "\n",
    "# update the bg of the first button to indicate current step\n",
    "navbarMenu.winfo_children()[0].winfo_children()[\n",
    "    0].config(bg=\"#0F1737\", fg=\"white\")\n",
    "\n",
    "# initialize frames\n",
    "pre_processingFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "uploadDataSetFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "clustersFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "algorithmsFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "visualizationFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "comparaisonFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "\n",
    "\n",
    "# abstracted functions for each step (implemented in each step's logic code cell)\n",
    "\n",
    "# dynamic parameter inputs creation\n",
    "def create_parameter_inputs():\n",
    "    pass\n",
    "\n",
    "# format visualization frame\n",
    "def format_visualization_frame():\n",
    "    pass\n",
    "\n",
    "# comparison auto run in comparison frame\n",
    "def auto_run_comparison():\n",
    "    pass\n",
    "\n",
    "\n",
    "# functions to handle step transitions\n",
    "def incrementStep():\n",
    "    global currentStep\n",
    "\n",
    "    if currentStep == 0:\n",
    "        uploadDataSetFrame.pack_forget()  # Hide upload frame\n",
    "        # Show pre-processing frame\n",
    "        pre_processingFrame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    elif currentStep == 1:\n",
    "        pre_processingFrame.pack_forget()\n",
    "        clustersFrame.pack(fill=tk.BOTH, expand=True)\n",
    "    elif currentStep == 2:\n",
    "        clustersFrame.pack_forget()\n",
    "        algorithmsFrame.pack(fill=tk.BOTH, expand=True)\n",
    "    elif currentStep == 3:\n",
    "        algorithmsFrame.pack_forget()\n",
    "        visualizationFrame.pack(fill=tk.BOTH, expand=True)\n",
    "        # Initialize with empty parameters\n",
    "        create_parameter_inputs()\n",
    "    elif currentStep == 4:\n",
    "        visualizationFrame.pack_forget()\n",
    "        comparaisonFrame.pack(fill=tk.BOTH, expand=True)\n",
    "        # show comparison frame info and plots\n",
    "        auto_run_comparison()\n",
    "\n",
    "    # update current step state\n",
    "    currentStep += 1\n",
    "\n",
    "    # update navbar button colors\n",
    "    if currentStep < len(menuButtons):\n",
    "        navbarMenu.winfo_children()[0].winfo_children(\n",
    "        )[currentStep].config(bg=\"#12172F\", fg=\"white\")\n",
    "\n",
    "    # update the color of the previous button\n",
    "    if currentStep - 1 >= 0:\n",
    "        navbarMenu.winfo_children()[0].winfo_children(\n",
    "        )[currentStep - 1].config(fg=\"white\", bg=\"#24367E\")\n",
    "\n",
    "\n",
    "def decrementStep():\n",
    "    global currentStep\n",
    "\n",
    "    if currentStep == 1:\n",
    "        pre_processingFrame.pack_forget()  # Hide pre-processing frame\n",
    "        uploadDataSetFrame.pack(fill=tk.BOTH, expand=True)  # Show upload frame\n",
    "\n",
    "    elif currentStep == 2:\n",
    "        clustersFrame.pack_forget()\n",
    "        pre_processingFrame.pack(fill=tk.BOTH, expand=True)\n",
    "    elif currentStep == 3:\n",
    "        algorithmsFrame.pack_forget()\n",
    "        clustersFrame.pack(fill=tk.BOTH, expand=True)\n",
    "    elif currentStep == 4:\n",
    "        visualizationFrame.pack_forget()\n",
    "        format_visualization_frame()\n",
    "        algorithmsFrame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    # update current step state\n",
    "    currentStep -= 1\n",
    "\n",
    "    # update navbar button colors\n",
    "    if currentStep + 1 < len(menuButtons):\n",
    "        navbarMenu.winfo_children()[0].winfo_children(\n",
    "        )[currentStep + 1].config(bg=\"#24367E\", fg=\"white\")\n",
    "\n",
    "    # update the color of the current button\n",
    "    if currentStep >= 0:\n",
    "        navbarMenu.winfo_children()[0].winfo_children(\n",
    "        )[currentStep].config(fg=\"white\", bg=\"#12172F\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc044ae",
   "metadata": {},
   "source": [
    "### 1 - b uplaod Data Set frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213dcc7",
   "metadata": {},
   "source": [
    "##### 1 - b Updload DataSet Frame design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "822370ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload dataSet frame\n",
    "uploadDataSetFrame = tk.Frame(window, bg=\"#f0f0f0\", height=400)\n",
    "uploadDataSetFrame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# center frame \n",
    "centerFrame = tk.Frame(uploadDataSetFrame, bg=\"#f0f0f0\")\n",
    "centerFrame.place(relx=0.5, rely=0.5, anchor=tk.CENTER)\n",
    "\n",
    "## label\n",
    "uploadLabel = tk.Label(centerFrame, text=\"Upload your data set here\", bg=\"#f0f0f0\", fg=\"#24367E\", font=(\"Arial\", 16))\n",
    "uploadLabel.pack(pady=20)\n",
    "\n",
    "## buttons frame\n",
    "buttonFrame = tk.Frame(centerFrame, bg=\"#f0f0f0\")\n",
    "buttonFrame.pack(pady=10)\n",
    "\n",
    "## upload button\n",
    "uploadDataSetButton = tk.Button(buttonFrame, text=\"Choose File\", bg=\"#7b9fc2\", fg=\"white\", font=(\"Arial\", 14), bd=0, relief='ridge', highlightthickness=5, highlightbackground=\"#7b9fc2\")\n",
    "uploadDataSetButton.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "## nextStep button\n",
    "nextStepUpload = tk.Button(buttonFrame, text=\"Next Step\", fg=\"white\", font=(\"Arial\", 14), bd=0, relief='ridge', highlightthickness=5, highlightbackground=\"#7b9fc2\")\n",
    "nextStepUpload.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "# nextStep button disabled initially\n",
    "nextStepUpload.config(state=tk.DISABLED)\n",
    "nextStepUpload.config(bg=\"#a0a0a0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50703be9",
   "metadata": {},
   "source": [
    "##### 1 - b upload logique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7ec5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import filedialog, messagebox\n",
    "import pandas as pd\n",
    "\n",
    "# global variable to store dataset\n",
    "dataSet_data = None\n",
    "\n",
    "# upload dataset function\n",
    "def uploadDataSet():\n",
    "    global dataSet_data\n",
    "    try:\n",
    "        \n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select CSV File\",\n",
    "            filetypes=[(\"CSV files\", \"*.csv\")]\n",
    "        )\n",
    "\n",
    "        if file_path:\n",
    "            # load the CSV file\n",
    "            dataSet_data = pd.read_csv(file_path)\n",
    "\n",
    "            # Mettre à jour le label pour indiquer le succès\n",
    "            uploadLabel.config(\n",
    "                text=f\"File uploaded successfully\\nFile: {file_path.split('/')[-1]}\\nRows: {len(dataSet_data)}, Columns: {len(dataSet_data.columns)}\")\n",
    "\n",
    "            uploadDataSetButton.config(text=\"Change File\")\n",
    "            \n",
    "            # Activer le bouton Next Step\n",
    "            nextStepUpload.config(state=tk.NORMAL)\n",
    "            nextStepUpload.config(bg=\"#2a4d6f\")\n",
    "            nextStepUpload.config(cursor=\"hand2\")\n",
    "\n",
    "            # success message box\n",
    "            messagebox.showinfo(\n",
    "                \"Success\", f\"CSV file loaded \\n Please click on the next step button.\")\n",
    "        else:\n",
    "            uploadLabel.config(text=\"No file selected\")\n",
    "\n",
    "    except pd.errors.EmptyDataError:\n",
    "        messagebox.showerror(\"Error\", \"The selected file is empty!\")\n",
    "        uploadLabel.config(text=\"Upload failed - Empty file\")\n",
    "\n",
    "    except pd.errors.ParserError:\n",
    "        messagebox.showerror(\"Error\", \"Error parsing the CSV file!\")\n",
    "        uploadLabel.config(text=\"Upload failed - Invalid CSV format\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "        uploadLabel.config(text=\"Upload failed - Error occurred\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# upload data set button assign function\n",
    "uploadDataSetButton.config(command=uploadDataSet)\n",
    "\n",
    "\n",
    "# next step buntton assign function\n",
    "nextStepUpload.config(command=incrementStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d2f5dc",
   "metadata": {},
   "source": [
    "### 1 - c Pre-processing Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82734c4",
   "metadata": {},
   "source": [
    "##### 1 -c pre processing frame design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "401ca592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import ttk, scrolledtext\n",
    "\n",
    "pre_processingFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "\n",
    "titleLabel = tk.Label(pre_processingFrame, text=\"Data Preprocessing\",\n",
    "                      bg=\"#f0f0f0\", fg=\"#24367E\", font=(\"Arial\", 18, \"bold\"))\n",
    "titleLabel.pack(pady=15)\n",
    "\n",
    "# steps buttons frame\n",
    "stepsFrame = tk.Frame(pre_processingFrame, bg=\"#f0f0f0\")\n",
    "stepsFrame.pack(pady=10, fill=tk.X, padx=30)\n",
    "\n",
    "# steps buttons grid configuration\n",
    "stepsFrame.grid_columnconfigure(0, weight=1)\n",
    "stepsFrame.grid_columnconfigure(1, weight=1)\n",
    "stepsFrame.grid_columnconfigure(2, weight=1)\n",
    "\n",
    "## each preprocessing step buttons\n",
    "\n",
    "# 1- missing values button\n",
    "missing_values_button = tk.Button(stepsFrame, text=\"1. Analyze & Fill Missing Values\",\n",
    "                                bg=\"#24367E\", fg=\"white\", font=(\"Arial\", 10, \"bold\"),\n",
    "                                  width=16, height=2, relief=\"raised\", bd=2)\n",
    "missing_values_button.grid(row=0, column=0, padx=5, pady=10, sticky=\"ew\")\n",
    "\n",
    "\n",
    "# 2- outliers button\n",
    "outliers_button = tk.Button(stepsFrame, text=\"2. Detect Outliers\",\n",
    "                            bg=\"#374451\", fg=\"white\", font=(\"Arial\", 10, \"bold\"),\n",
    "                            width=16, height=2, relief=\"raised\", bd=2)\n",
    "outliers_button.grid(row=0, column=1, padx=5, pady=10, sticky=\"ew\")\n",
    "outliers_button.config(state=tk.DISABLED)\n",
    "\n",
    "# 3- normalization button\n",
    "normalization_button = tk.Button(stepsFrame, text=\"3. Normalize Data\",\n",
    "                                 bg=\"#374451\", fg=\"white\", font=(\"Arial\", 10, \"bold\"),\n",
    "                                 width=16, height=2, relief=\"raised\", bd=2)\n",
    "normalization_button.grid(row=0, column=2, padx=5, pady=10, sticky=\"ew\")\n",
    "normalization_button.config(state=tk.DISABLED)\n",
    "\n",
    "# nextStep button\n",
    "nextStepPreprocessing = tk.Button(stepsFrame, text=\"Next Step\",\n",
    "                                 bg=\"#374451\", fg=\"white\", font=(\"Arial\", 10, \"bold\"),\n",
    "                                 width=16, height=2, relief=\"raised\", bd=2)\n",
    "nextStepPreprocessing.grid(row=0, column=3, columnspan=3, pady=10)\n",
    "nextStepPreprocessing.config(state=tk.DISABLED)\n",
    "\n",
    "\n",
    "separator = tk.Frame(pre_processingFrame, height=2, bg=\"#7b9fc2\")\n",
    "separator.pack(fill=tk.X, padx=30, pady=15)\n",
    "\n",
    "# results label\n",
    "resultsLabel = tk.Label(pre_processingFrame, text=\"Results:\",\n",
    "                        bg=\"#f0f0f0\", fg=\"#24367E\", font=(\"Arial\", 14, \"bold\"))\n",
    "resultsLabel.pack(anchor=tk.W, padx=30)\n",
    "\n",
    "# results frame\n",
    "resultsFrame = tk.Frame(pre_processingFrame, bg=\"#f0f0f0\")\n",
    "resultsFrame.pack(pady=5, fill=tk.BOTH, expand=True, padx=30)\n",
    "\n",
    "# text area with scrollbar\n",
    "resultsText = scrolledtext.ScrolledText(resultsFrame,\n",
    "                                        height=12,\n",
    "                                        font=(\"Courier\", 12),\n",
    "                                        bg=\"white\",\n",
    "                                        fg=\"#333333\",\n",
    "                                        wrap=\"word\",\n",
    "                                        relief=\"sunken\",\n",
    "                                        bd=2)\n",
    "resultsText.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# initlialize text area\n",
    "resultsText.insert(tk.END, \"Preprocessing panel : \\n\")\n",
    "resultsText.insert(tk.END, \"=\" * 25 + \"\\n\\n\")\n",
    "resultsText.insert(\n",
    "    tk.END, \"Select The analysis & fill missing values step to begin.\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c560a8",
   "metadata": {},
   "source": [
    "##### 1 - c pre processing logique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a84c98b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing steps logic functions\n",
    "\n",
    "# 1- analyze & fill missing values step\n",
    "\n",
    "# missing values function\n",
    "def analyze_missing_values_logic():\n",
    "    global dataSet_data\n",
    "\n",
    "    # Check if data exists\n",
    "    if dataSet_data is None:\n",
    "        return {\n",
    "            'error': True,\n",
    "            'message': 'No dataset uploaded. Please go back and upload a CSV file first.',\n",
    "            'data': None\n",
    "        }\n",
    "\n",
    "    # Store original data info\n",
    "    original_rows = dataSet_data.shape[0]\n",
    "    original_cols = dataSet_data.shape[1]\n",
    "\n",
    "    # Count missing values ('?' characters)\n",
    "    missing_counts = {}\n",
    "    for col in dataSet_data.columns:\n",
    "        missing_count = (dataSet_data[col] == '?').sum()\n",
    "        missing_counts[col] = missing_count\n",
    "\n",
    "    #DataFrame for missing values\n",
    "    import pandas as pd\n",
    "    missing_df = pd.DataFrame(list(missing_counts.items()),\n",
    "                              columns=['Column', 'Missing_Values'])\n",
    "    missing_df['Percentage'] = (\n",
    "        missing_df['Missing_Values'] / len(dataSet_data)) * 100\n",
    "    missing_df = missing_df.sort_values('Missing_Values', ascending=False)\n",
    "\n",
    "    columns_with_missing = missing_df[missing_df['Missing_Values'] > 0]\n",
    "    total_missing = missing_df['Missing_Values'].sum()\n",
    "\n",
    "    numeric_cols = dataSet_data.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = dataSet_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "    numeric_missing = 0\n",
    "    categorical_missing = 0\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        numeric_missing += (dataSet_data[col] == '?').sum()\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        categorical_missing += (dataSet_data[col] == '?').sum()\n",
    "\n",
    "    cleaned_data = dataSet_data.copy()\n",
    "\n",
    "    # drop columns with more than 50% missing values\n",
    "    high_missing_cols = columns_with_missing[columns_with_missing['Percentage'] > 50]['Column'].tolist(\n",
    "    )\n",
    "    if high_missing_cols:\n",
    "        cleaned_data = cleaned_data.drop(columns=high_missing_cols)\n",
    "\n",
    "    # numerical columns : fill '?' with median\n",
    "    numeric_cols_cleaned = cleaned_data.select_dtypes(\n",
    "        include=['number']).columns\n",
    "    for col in numeric_cols_cleaned:\n",
    "        if (cleaned_data[col] == '?').sum() > 0:\n",
    "            # Convert '?' to NaN for numerical calculation\n",
    "            temp_col = cleaned_data[col].replace('?', pd.NA)\n",
    "            temp_col = pd.to_numeric(temp_col, errors='coerce')\n",
    "            median_value = temp_col.median()\n",
    "            cleaned_data[col] = cleaned_data[col].replace('?', median_value)\n",
    "\n",
    "    # categorical columns : fill '?' with mode\n",
    "    categorical_cols_cleaned = cleaned_data.select_dtypes(\n",
    "        include=['object']).columns\n",
    "    for col in categorical_cols_cleaned:\n",
    "        if (cleaned_data[col] == '?').sum() > 0:\n",
    "            temp_col = cleaned_data[col][cleaned_data[col] != '?']\n",
    "            if len(temp_col) > 0:\n",
    "                mode_value = temp_col.mode()\n",
    "                if len(mode_value) > 0:\n",
    "                    cleaned_data[col] = cleaned_data[col].replace(\n",
    "                        '?', mode_value.iloc[0])\n",
    "                else:\n",
    "                    cleaned_data[col] = cleaned_data[col].replace(\n",
    "                        '?', 'Unknown')\n",
    "            else:\n",
    "                cleaned_data[col] = cleaned_data[col].replace('?', 'Unknown')\n",
    "\n",
    "    # update global dataset with cleaned data\n",
    "    dataSet_data = cleaned_data\n",
    "\n",
    "    return {\n",
    "        'error': False,\n",
    "        'original_shape': (original_rows, original_cols),\n",
    "        'new_shape': cleaned_data.shape,\n",
    "        'total_missing': int(total_missing),\n",
    "        'numeric_missing': int(numeric_missing),\n",
    "        'categorical_missing': int(categorical_missing),\n",
    "        'columns_with_missing': columns_with_missing.set_index('Column')['Missing_Values'].to_dict(),\n",
    "        'missing_percentages': columns_with_missing.set_index('Column')['Percentage'].to_dict(),\n",
    "        'dropped_columns': high_missing_cols,\n",
    "        'numeric_columns_filled': [col for col in numeric_cols_cleaned if col in missing_counts and missing_counts[col] > 0],\n",
    "        'categorical_columns_filled': [col for col in categorical_cols_cleaned if col in missing_counts and missing_counts[col] > 0],\n",
    "        'data_cleaned': True\n",
    "    }\n",
    "\n",
    "# GUI update function with results\n",
    "def analyze_missing_values():\n",
    "    global dataSet_data\n",
    "\n",
    "    resultsText.delete(1.0, tk.END)\n",
    "\n",
    "    # get cleaned data set\n",
    "    result = analyze_missing_values_logic()\n",
    "\n",
    "    if result['error']:\n",
    "        resultsText.insert(tk.END, \"ERROR: \" + result['message'] + \"\\n\\n\")\n",
    "        return\n",
    "\n",
    "    resultsText.insert(tk.END, \"Missing values analysis:\\n\")\n",
    "    resultsText.insert(tk.END, \"=\" * 25 + \"\\n\\n\")\n",
    "\n",
    "    resultsText.insert(tk.END, f\"Dataset Info:\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- Original shape: {result['original_shape'][0]} rows, {result['original_shape'][1]} columns\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- New shape: {result['new_shape'][0]} rows, {result['new_shape'][1]} columns\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- Total missing values found: {result['total_missing']}\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- Numeric missing values: {result['numeric_missing']}\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- Categorical missing values: {result['categorical_missing']}\\n\\n\")\n",
    "\n",
    "    # missing values per column\n",
    "    if result['columns_with_missing']:\n",
    "        resultsText.insert(tk.END, \"Missing Values by Column:\\n\")\n",
    "        resultsText.insert(tk.END, \"-\" * 50 + \"\\n\")\n",
    "        for column, missing_count in result['columns_with_missing'].items():\n",
    "            percentage = result['missing_percentages'][column]\n",
    "            resultsText.insert(\n",
    "                tk.END, f\"{column}: {missing_count} values ({percentage:.1f}%)\\n\")\n",
    "        resultsText.insert(tk.END, \"\\n\")\n",
    "    else:\n",
    "        resultsText.insert(\n",
    "            tk.END, \"No missing values found in the dataset.\\n\\n\")\n",
    "\n",
    "    # Display actions taken\n",
    "    resultsText.insert(tk.END, \"Actions Performed:\\n\")\n",
    "    resultsText.insert(tk.END, \"-\" * 20 + \"\\n\")\n",
    "\n",
    "    # dropped columns\n",
    "    if result['dropped_columns']:\n",
    "        resultsText.insert(\n",
    "            tk.END, f\"Dropped columns (>50% missing): {len(result['dropped_columns'])} columns\\n\")\n",
    "        for col in result['dropped_columns']:\n",
    "            resultsText.insert(tk.END, f\"  - {col}\\n\")\n",
    "    else:\n",
    "        resultsText.insert(tk.END, \"No columns dropped\\n\")\n",
    "\n",
    "    # cleaned numeric columns\n",
    "    if result['numeric_columns_filled']:\n",
    "        resultsText.insert(\n",
    "            tk.END, f\"Numeric columns filled with median: {len(result['numeric_columns_filled'])} columns\\n\")\n",
    "        for col in result['numeric_columns_filled']:\n",
    "            resultsText.insert(tk.END, f\"  - {col}\\n\")\n",
    "\n",
    "    # cleaned categorical columns\n",
    "    if result['categorical_columns_filled']:\n",
    "        resultsText.insert(\n",
    "            tk.END, f\"\\nCategorical columns filled with mode: {len(result['categorical_columns_filled'])} columns\\n\")\n",
    "        for col in result['categorical_columns_filled']:\n",
    "            resultsText.insert(tk.END, f\"  - {col}\\n\")\n",
    "\n",
    "    # final status\n",
    "    resultsText.insert(\n",
    "        tk.END, \"\\nStatus: Missing values analysis completed successfully.\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, \"Dataset is now ready for outlier detection , please proceed to outlier detection\\n\")\n",
    "\n",
    "    # update button states and style\n",
    "    missing_values_button.config(state=tk.DISABLED, bg=\"#374451\")\n",
    "    outliers_button.config(state=tk.NORMAL, bg=\"#24367E\")\n",
    "    normalization_button.config(state=tk.DISABLED, bg=\"#374451\")\n",
    "\n",
    "# assign function to the missing values step button\n",
    "missing_values_button.config(command=analyze_missing_values)\n",
    "\n",
    "\n",
    "# 2- detect outliers step\n",
    "\n",
    "# outliers detection function\n",
    "def analyze_outliers_logic():\n",
    "    global dataSet_data\n",
    "\n",
    "    if dataSet_data is None:\n",
    "        return {\n",
    "            'error': True,\n",
    "            'message': 'No dataset uploaded. Please go back and upload a CSV file first.',\n",
    "            'data': None\n",
    "        }\n",
    "\n",
    "    numeric_cols = dataSet_data.select_dtypes(\n",
    "        include=['number']).columns.tolist()\n",
    "\n",
    "    if not numeric_cols:\n",
    "        return {\n",
    "            'error': True,\n",
    "            'message': 'No numeric columns found in the dataset.',\n",
    "            'data': None\n",
    "        }\n",
    "\n",
    "    outliers_info = {}\n",
    "    total_outliers = 0\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        # drop NaN values\n",
    "        data = pd.to_numeric(dataSet_data[col], errors='coerce').dropna()\n",
    "\n",
    "        if len(data) > 0:\n",
    "            Q1 = data.quantile(0.25)\n",
    "            Q3 = data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "            outlier_count = len(outliers)\n",
    "\n",
    "            if outlier_count > 0:\n",
    "                outliers_info[col] = {\n",
    "                    'count': outlier_count,\n",
    "                    'lower_bound': lower_bound,\n",
    "                    'upper_bound': upper_bound,\n",
    "                    'percentage': (outlier_count / len(data)) * 100\n",
    "                }\n",
    "                total_outliers += outlier_count\n",
    "\n",
    "    return {\n",
    "        'error': False,\n",
    "        'numeric_columns': len(numeric_cols),\n",
    "        'total_outliers': total_outliers,\n",
    "        'outliers_info': outliers_info,\n",
    "        'columns_with_outliers': len(outliers_info),\n",
    "        'data_processed': True\n",
    "    }\n",
    "\n",
    "# GUI update function with results\n",
    "def analyze_outliers():\n",
    "    global dataSet_data\n",
    "\n",
    "    resultsText.delete(1.0, tk.END)\n",
    "\n",
    "    # get outliers analysis result\n",
    "    result = analyze_outliers_logic()\n",
    "\n",
    "    if result['error']:\n",
    "        resultsText.insert(tk.END, \"ERROR: \" + result['message'] + \"\\n\\n\")\n",
    "        return\n",
    "\n",
    "    resultsText.insert(tk.END, \"Outliers detection analysis\\n\")\n",
    "    resultsText.insert(tk.END, \"=\" * 30 + \"\\n\\n\")\n",
    "\n",
    "    resultsText.insert(tk.END, f\"Outliers Detection Info:\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- Numeric columns analyzed: {result['numeric_columns']}\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- Columns with outliers: {result['columns_with_outliers']}\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- Total outliers found: {result['total_outliers']}\\n\\n\")\n",
    "\n",
    "    # outliers per column\n",
    "    if result['outliers_info']:\n",
    "        resultsText.insert(tk.END, \"Outliers by Column:\\n\")\n",
    "        resultsText.insert(tk.END, \"-\" * 25 + \"\\n\")\n",
    "\n",
    "        for column, info in result['outliers_info'].items():\n",
    "            resultsText.insert(tk.END, f\"{column}:\\n\")\n",
    "            resultsText.insert(\n",
    "                tk.END, f\"  - Number of outliers: {info['count']}\\n\")\n",
    "            resultsText.insert(\n",
    "                tk.END, f\"  - Percentage: {info['percentage']:.1f}%\\n\")\n",
    "            resultsText.insert(\n",
    "                tk.END, f\"  - Valid range: [{info['lower_bound']:.2f}, {info['upper_bound']:.2f}]\\n\")\n",
    "            resultsText.insert(tk.END, \"\\n\")\n",
    "    else:\n",
    "        resultsText.insert(\n",
    "            tk.END, \"No outliers found in any numeric columns.\\n\\n\")\n",
    "\n",
    "    resultsText.insert(\n",
    "        tk.END, \"Status: Outliers detection completed successfully.\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, \"Dataset is now ready for normalization , please proceed to data normalization\\n\")\n",
    "\n",
    "    # update preprocessing button states and style\n",
    "    missing_values_button.config(state=tk.DISABLED, bg=\"#374451\")\n",
    "    outliers_button.config(state=tk.DISABLED, bg=\"#374451\")\n",
    "    normalization_button.config(state=tk.NORMAL, bg=\"#24367E\")\n",
    "\n",
    "# assign function to the outliers detection step button\n",
    "outliers_button.config(command=analyze_outliers)\n",
    "\n",
    "\n",
    "# 3 - normalize data step\n",
    "\n",
    "# data normalization function\n",
    "def normalize_data_logic():\n",
    "    global dataSet_data\n",
    "\n",
    "    if dataSet_data is None:\n",
    "        return {\n",
    "            'error': True,\n",
    "            'message': 'No dataset uploaded. Please go back and upload a CSV file first.',\n",
    "            'data': None\n",
    "        }\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "    original_shape = dataSet_data.shape\n",
    "\n",
    "    numeric_cols = dataSet_data.select_dtypes(\n",
    "        include=['number']).columns.tolist()\n",
    "    categorical_cols = dataSet_data.select_dtypes(\n",
    "        include=['object']).columns.tolist()\n",
    "\n",
    "    encoders = {}\n",
    "    df_encoded = dataSet_data.copy()\n",
    "\n",
    "    last_column = dataSet_data.columns[-1]\n",
    "\n",
    "    # encode categorical columns \n",
    "    encoded_categorical = []\n",
    "    for col in categorical_cols:\n",
    "        if col in df_encoded.columns and col != last_column:\n",
    "            le = LabelEncoder()\n",
    "            df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "            encoders[col] = le\n",
    "            encoded_categorical.append(col)\n",
    "\n",
    "    if last_column in categorical_cols:\n",
    "        le_target = LabelEncoder()\n",
    "        df_encoded[last_column] = le_target.fit_transform(\n",
    "            df_encoded[last_column])\n",
    "        encoders[last_column] = le_target\n",
    "        encoded_categorical.append(last_column)\n",
    "\n",
    "    X = df_encoded.drop(last_column, axis=1)\n",
    "    y = df_encoded[last_column]\n",
    "\n",
    "    # get numeric features\n",
    "    numeric_features = [col for col in numeric_cols if col in X.columns]\n",
    "\n",
    "    # Copy for normalization\n",
    "    X_original = X.copy()\n",
    "    X_scaled = X.copy()\n",
    "\n",
    "    # apply standardScaler (z-score normalization)\n",
    "    scaler = None\n",
    "    scaled_features = []\n",
    "    if numeric_features:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "        scaled_features = numeric_features\n",
    "\n",
    "    # update global dataset with normalized data\n",
    "    dataSet_data = X_scaled.copy()\n",
    "    dataSet_data[last_column] = y\n",
    "\n",
    "    return {\n",
    "        'error': False,\n",
    "        'original_shape': original_shape,\n",
    "        'new_shape': dataSet_data.shape,\n",
    "        'categorical_columns': len(categorical_cols),\n",
    "        'numeric_columns': len(numeric_cols),\n",
    "        'encoded_categorical': encoded_categorical,\n",
    "        'scaled_features': scaled_features,\n",
    "        'has_target': True,\n",
    "        'data_normalized': True\n",
    "    }\n",
    "\n",
    "# GUI update function with results\n",
    "def normalize_data():\n",
    "    global dataSet_data\n",
    "\n",
    "    resultsText.delete(1.0, tk.END)\n",
    "\n",
    "    # get normalization result\n",
    "    result = normalize_data_logic()\n",
    "\n",
    "    if result['error']:\n",
    "        resultsText.insert(tk.END, \"ERROR: \" + result['message'] + \"\\n\\n\")\n",
    "        return\n",
    "\n",
    "    resultsText.insert(tk.END, \"Data normalization\\n\")\n",
    "    resultsText.insert(tk.END, \"=\" * 25 + \"\\n\")\n",
    "\n",
    "    resultsText.insert(\n",
    "        tk.END, \"Z-score normalization applied to numeric features.\\n\")\n",
    "\n",
    "    resultsText.insert(tk.END, f\"Dataset Info:\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- Categorical columns: {result['categorical_columns']}\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, f\"- Numeric columns: {result['numeric_columns']}\\n\")\n",
    "\n",
    "    # encoding results\n",
    "    resultsText.insert(tk.END, \"Encoding Results:\\n\")\n",
    "    resultsText.insert(tk.END, \"-\" * 20 + \"\\n\")\n",
    "    if result['encoded_categorical']:\n",
    "        resultsText.insert(\n",
    "            tk.END, f\"Encoded categorical columns: {len(result['encoded_categorical'])}\\n\")\n",
    "        for col in result['encoded_categorical']:\n",
    "            resultsText.insert(tk.END, f\"  - {col}\\n\")\n",
    "    else:\n",
    "        resultsText.insert(tk.END, \"No categorical columns encoded\\n\")\n",
    "\n",
    "    # normalization results\n",
    "    resultsText.insert(tk.END, \"\\nScaling Results:\\n\")\n",
    "    resultsText.insert(tk.END, \"-\" * 16 + \"\\n\")\n",
    "    if result['scaled_features']:\n",
    "        resultsText.insert(\n",
    "            tk.END, f\"Scaled numeric features: {len(result['scaled_features'])}\\n\")\n",
    "        for col in result['scaled_features']:\n",
    "            resultsText.insert(tk.END, f\"  - {col}\\n\")\n",
    "    else:\n",
    "        resultsText.insert(tk.END, \"No numeric features scaled\\n\")\n",
    "\n",
    "    resultsText.insert(\n",
    "        tk.END, \"\\nStatus: Data normalization completed successfully.\\n\")\n",
    "    resultsText.insert(\n",
    "        tk.END, \"Dataset is now ready for clustering analysis , please proceed to the next step.\\n\")\n",
    "\n",
    "    # Uupdate preprocessing button states and style\n",
    "    missing_values_button.config(state=tk.DISABLED, bg=\"#374451\")\n",
    "    outliers_button.config(state=tk.DISABLED, bg=\"#374451\")\n",
    "    normalization_button.config(state=tk.DISABLED, bg=\"#374451\")\n",
    "    nextStepPreprocessing.config(state=tk.NORMAL, bg=\"#24367E\")\n",
    "\n",
    "# assign function to the normalization step button\n",
    "normalization_button.config(command=normalize_data)\n",
    "\n",
    "\n",
    "\n",
    "# advance to next step after preprocessing\n",
    "nextStepPreprocessing.config(command=incrementStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f141614",
   "metadata": {},
   "source": [
    "### 1 - d Clusters Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef2406",
   "metadata": {},
   "source": [
    "##### 1 -d Clusters frame design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c14846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters frame \n",
    "\n",
    "clustersFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "\n",
    "\n",
    "clusterTitleLabel = tk.Label(clustersFrame, text=\"Cluster Analysis\",\n",
    "                             bg=\"#f0f0f0\", fg=\"#24367E\", font=(\"Arial\", 18, \"bold\"))\n",
    "clusterTitleLabel.pack(pady=10)\n",
    "\n",
    "# main cluster frame\n",
    "mainClusterFrame = tk.Frame(clustersFrame, bg=\"#f0f0f0\")\n",
    "mainClusterFrame.pack(fill=tk.BOTH, expand=True, padx=20, pady=10)\n",
    "\n",
    "# main cluster frame grid configuration\n",
    "mainClusterFrame.grid_columnconfigure(0, weight=4) \n",
    "mainClusterFrame.grid_columnconfigure(1, weight=2) \n",
    "mainClusterFrame.grid_rowconfigure(0, weight=1)\n",
    "\n",
    "# left part: graph area\n",
    "graphFrame = tk.Frame(mainClusterFrame, bg=\"white\", relief=\"sunken\", bd=2)\n",
    "graphFrame.grid(row=0, column=0, sticky=\"nsew\", padx=(0, 10))\n",
    "\n",
    "# right part: metrics area\n",
    "metricsFrame = tk.Frame(mainClusterFrame, bg=\"#f8f9fa\", relief=\"raised\", bd=2)\n",
    "metricsFrame.grid(row=0, column=1, sticky=\"nsew\")\n",
    "\n",
    "\n",
    "metricsTitle = tk.Label(metricsFrame, text=\"Cluster Metrics\",\n",
    "                        bg=\"#f8f9fa\", fg=\"#24367E\", font=(\"Arial\", 14, \"bold\"))\n",
    "metricsTitle.pack(pady=10)\n",
    "\n",
    "# metrics labels\n",
    "optimalKLabel = tk.Label(metricsFrame, text=\"Optimal K: Calculating...\",\n",
    "                         bg=\"#f8f9fa\", fg=\"#333\", font=(\"Arial\", 12))\n",
    "optimalKLabel.pack(pady=10)\n",
    "\n",
    "silhouetteLabel = tk.Label(metricsFrame, text=\"Silhouette Score: -\",\n",
    "                           bg=\"#f8f9fa\", fg=\"#333\", font=(\"Arial\", 12))\n",
    "silhouetteLabel.pack(pady=5)\n",
    "\n",
    "# analyze clusters button\n",
    "analyzeBtn = tk.Button(metricsFrame, text=\"Analyze Clusters\",\n",
    "                       bg=\"#7b9fc2\", fg=\"white\", font=(\"Arial\", 12, \"bold\"),\n",
    "                       width=15, height=2, relief=\"raised\", bd=2)\n",
    "analyzeBtn.pack(pady=20)\n",
    "\n",
    "# next step button\n",
    "nextStepClusters = tk.Button(metricsFrame, text=\"Next Step\",\n",
    "                             bg=\"#374451\", fg=\"white\", font=(\"Arial\", 12, \"bold\"),\n",
    "                             width=15, height=2, relief=\"raised\", bd=2)\n",
    "nextStepClusters.pack(pady=10)\n",
    "nextStepClusters.config(state=tk.DISABLED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db59776",
   "metadata": {},
   "source": [
    "##### 1 -d Clusters frame logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5937901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# clusters frame logic functions & variables\n",
    "optimal_k_global = None\n",
    "silhouette_score_global = None\n",
    "\n",
    "# metrics functions\n",
    "\n",
    "# generate sample data function (if empty dataset)\n",
    "def generate_sample_data():\n",
    "    X, _ = make_blobs(n_samples=300, centers=4, n_features=2,\n",
    "                      random_state=42, cluster_std=0.60)\n",
    "    return X\n",
    "\n",
    "\n",
    "# calculate elbow method metrics function\n",
    "def calculate_elbow_metrics(data):\n",
    "\n",
    "    k_range = range(1, 11)\n",
    "    wcss_values = []\n",
    "    silhouette_scores = []\n",
    "\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(data)\n",
    "        wcss_values.append(kmeans.inertia_)\n",
    "\n",
    "        if k > 1: \n",
    "            labels = kmeans.labels_\n",
    "            sil_score = silhouette_score(data, labels)\n",
    "            silhouette_scores.append(sil_score)\n",
    "        else:\n",
    "            silhouette_scores.append(0)\n",
    "\n",
    "    return k_range, wcss_values, silhouette_scores\n",
    "\n",
    "\n",
    "# get the optimal number of clusters function\n",
    "def find_optimal_k(wcss_values):\n",
    "    # simple gradient method\n",
    "    diffs = np.diff(wcss_values, 2)\n",
    "    optimal_k = np.argmax(diffs) + 2\n",
    "    return min(optimal_k, 8)\n",
    "\n",
    "\n",
    "# plot elbow curve function\n",
    "def plot_elbow_curve(k_range, wcss_values, optimal_k):\n",
    "    for widget in graphFrame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(k_range, wcss_values, 'bo-', linewidth=2, markersize=6)\n",
    "    ax.scatter(optimal_k, wcss_values[optimal_k-1],\n",
    "               color='red', s=100, zorder=5)\n",
    "    ax.annotate(f'Optimal K = {optimal_k}',\n",
    "                xy=(optimal_k, wcss_values[optimal_k-1]),\n",
    "                xytext=(optimal_k+1, wcss_values[optimal_k-1]+200),\n",
    "                arrowprops=dict(arrowstyle='->', color='red'),\n",
    "                fontsize=10, color='red')\n",
    "\n",
    "    ax.set_title('Elbow Method for Optimal K', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Number of Clusters (K)')\n",
    "    ax.set_ylabel('WCSS')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # integrate figure into Tkinter\n",
    "    canvas = FigureCanvasTkAgg(fig, graphFrame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "\n",
    "# main analyze clusters function\n",
    "def analyze_clusters():\n",
    "\n",
    "    global dataSet_data, optimal_k_global, silhouette_score_global\n",
    "\n",
    "    if dataSet_data is not None:\n",
    "        # select only numeric columns\n",
    "        last_column = dataSet_data.columns[-1]\n",
    "        features_data = dataSet_data.drop(last_column, axis=1)\n",
    "        numeric_data = features_data.select_dtypes(include=[np.number])\n",
    "\n",
    "        if len(numeric_data.columns) == 0:\n",
    "           # no numeric data so use random sample data        \n",
    "            data = generate_sample_data()\n",
    "            optimalKLabel.config(text=\"No numeric features found\")\n",
    "            silhouetteLabel.config(text=\"Using sample data\")\n",
    "        else:\n",
    "            data = numeric_data.values\n",
    "            optimalKLabel.config(text=\"Analyzing real data...\")\n",
    "            silhouetteLabel.config(text=\"Computing metrics...\")\n",
    "    else:\n",
    "        # no data loaded, use sample data\n",
    "        data = generate_sample_data()\n",
    "        optimalKLabel.config(text=\"No dataset loaded\")\n",
    "        silhouetteLabel.config(text=\"Using sample data\")\n",
    "\n",
    "    try:\n",
    "        # calculate metrics\n",
    "        k_range, wcss_values, silhouette_scores = calculate_elbow_metrics(data)\n",
    "        optimal_k = find_optimal_k(wcss_values)\n",
    "\n",
    "        # store global values\n",
    "        optimal_k_global = optimal_k\n",
    "        silhouette_score_global = silhouette_scores[optimal_k-1]\n",
    "\n",
    "        # plot elbow curve\n",
    "        plot_elbow_curve(k_range, wcss_values, optimal_k)\n",
    "\n",
    "        # update GUI labels with results\n",
    "        optimalKLabel.config(text=f\"Optimal K: {optimal_k}\")\n",
    "        silhouetteLabel.config(\n",
    "            text=f\"Silhouette Score: {silhouette_scores[optimal_k-1]:.3f}\")\n",
    "\n",
    "        # enable next step button\n",
    "        nextStepClusters.config(state=tk.NORMAL)\n",
    "        nextStepClusters.config(bg=\"#24367E\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in cluster analysis: {e}\")\n",
    "        optimalKLabel.config(text=\"Error in analysis\")\n",
    "        silhouetteLabel.config(text=\"Please try again\")\n",
    "\n",
    "\n",
    "# analyze clusters button assign analyze_clusters function\n",
    "analyzeBtn.config(command=analyze_clusters)\n",
    "\n",
    "# next step button\n",
    "nextStepClusters.config(command=incrementStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024c59b",
   "metadata": {},
   "source": [
    "### 1 - e Algorithms frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f362f",
   "metadata": {},
   "source": [
    "##### 1 - e algorithmes object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3d3f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms object\n",
    "algorithms = {\n",
    "    \"Partitioning\": {\n",
    "        \"description\": \"Divise les données en k partitions non-chevauchantes où chaque point appartient à exactement un cluster.\",\n",
    "        \"image\": \"https://files.edgestore.dev/643tuked7tdgupmf/publicFiles/_public/5e568f84-ada0-488c-b7a9-8de92bed1d5f.png\",\n",
    "        \"algorithms\": {\n",
    "            \"K-Means\": {\n",
    "                \"parameters\": [\"n_clusters\", \"distance_metric\", 'max_iter'],\n",
    "            },\n",
    "            \"K-Medoids\": {\n",
    "                \"parameters\": [\"n_clusters\", \"distance_metric\", \"max_iter\"],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"Hierarchical\": {\n",
    "        \"description\": \"Crée une hiérarchie de clusters en formant un arbre de clusters (dendrogramme).\",\n",
    "        \"image\": \"https://files.edgestore.dev/643tuked7tdgupmf/publicFiles/_public/321e89c8-098c-4cf8-93ec-2de7ce5ddb02.png\",\n",
    "        \"algorithms\": {\n",
    "            \"AGNES\": {\n",
    "                \"parameters\": [\"n_clusters\", \"linkage\", 'distance_metric'],\n",
    "            },\n",
    "            \"DIANA\": {\n",
    "                \"parameters\": [\"n_clusters\", 'distance_metric'],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"Density-based\": {\n",
    "        \"description\": \"Identifie les clusters comme des zones denses séparées par des zones de faible densité.\",\n",
    "        \"image\": \"https://files.edgestore.dev/643tuked7tdgupmf/publicFiles/_public/f5038606-6641-4c31-8a12-69b2ac3d9873.png\",\n",
    "        \"algorithms\": {\n",
    "            \"DBSCAN\": {\n",
    "                \"parameters\": [\"eps\", \"min_samples\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f9d2a",
   "metadata": {},
   "source": [
    "##### 1 - e algorithms frame design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bec9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageTk\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# algorithms frame\n",
    "algorithmsFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "\n",
    "algorithmsTitleLabel = tk.Label(algorithmsFrame, text=\"Clustering Algorithms\",\n",
    "                                bg=\"#f0f0f0\", fg=\"#24367E\", font=(\"Arial\", 18, \"bold\"))\n",
    "algorithmsTitleLabel.pack(pady=10)\n",
    "\n",
    "# algorithm type buttons frame\n",
    "typeButtonsFrame = tk.Frame(algorithmsFrame, bg=\"#f0f0f0\")\n",
    "typeButtonsFrame.pack(pady=10, fill=tk.X, padx=30)\n",
    "\n",
    "# buttons frame grid configuration\n",
    "typeButtonsFrame.grid_columnconfigure(0, weight=1)\n",
    "typeButtonsFrame.grid_columnconfigure(1, weight=1)\n",
    "typeButtonsFrame.grid_columnconfigure(2, weight=1)\n",
    "typeButtonsFrame.grid_columnconfigure(3, weight=1)\n",
    "typeButtonsFrame.grid_columnconfigure(4, weight=1)\n",
    "\n",
    "# all algorithms types button\n",
    "\n",
    "# 1 - partitioning button\n",
    "partitioningBtn = tk.Button(typeButtonsFrame, text=\"Partitioning\",\n",
    "                            bg=\"#24367E\", fg=\"white\", font=(\"Arial\", 12, \"bold\"),\n",
    "                            width=15, height=2, relief=\"raised\", bd=2)\n",
    "partitioningBtn.grid(row=0, column=1, padx=10, pady=10, sticky=\"ew\")\n",
    "\n",
    "# 2 - hierarchical button\n",
    "hierarchicalBtn = tk.Button(typeButtonsFrame, text=\"Hierarchical\",\n",
    "                            bg=\"#374451\", fg=\"white\", font=(\"Arial\", 12, \"bold\"),\n",
    "                            width=15, height=2, relief=\"raised\", bd=2)\n",
    "hierarchicalBtn.grid(row=0, column=2, padx=10, pady=10, sticky=\"ew\")\n",
    "\n",
    "# 3 - density-based button\n",
    "densityBtn = tk.Button(typeButtonsFrame, text=\"Density-based\",\n",
    "                       bg=\"#374451\", fg=\"white\", font=(\"Arial\", 12, \"bold\"),\n",
    "                       width=15, height=2, relief=\"raised\", bd=2)\n",
    "densityBtn.grid(row=0, column=3, padx=10, pady=10, sticky=\"ew\")\n",
    "\n",
    "\n",
    "separator = tk.Frame(algorithmsFrame, height=2, bg=\"#7b9fc2\")\n",
    "separator.pack(fill=tk.X, padx=30, pady=15)\n",
    "\n",
    "# main content frame\n",
    "mainContentFrame = tk.Frame(algorithmsFrame, bg=\"#f0f0f0\")\n",
    "mainContentFrame.pack(fill=tk.BOTH, expand=True, padx=20, pady=10)\n",
    "\n",
    "# main content frame grid configuration\n",
    "mainContentFrame.grid_columnconfigure(0, weight=2)  \n",
    "mainContentFrame.grid_columnconfigure(1, weight=1)  \n",
    "mainContentFrame.grid_rowconfigure(0, weight=1)\n",
    "\n",
    "# description part\n",
    "descriptionFrame = tk.Frame(\n",
    "    mainContentFrame, bg=\"white\", relief=\"sunken\", bd=2)\n",
    "descriptionFrame.grid(row=0, column=0, sticky=\"nsew\", padx=(0, 10))\n",
    "\n",
    "# description text area\n",
    "typeDescText = scrolledtext.ScrolledText(descriptionFrame, height=8, width=50,\n",
    "                                         font=(\"Arial\", 10), bg=\"#f9f9f9\",\n",
    "                                         wrap=\"word\", relief=\"flat\", bd=1)\n",
    "typeDescText.pack(pady=2, padx=10, fill=tk.X)\n",
    "\n",
    "# algorithms list frame\n",
    "algorithmsListFrame = tk.Frame(descriptionFrame, bg=\"white\")\n",
    "algorithmsListFrame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)\n",
    "\n",
    "# right part: image and next step\n",
    "imageFrame = tk.Frame(mainContentFrame, bg=\"#f8f9fa\", relief=\"raised\", bd=2)\n",
    "imageFrame.grid(row=0, column=1, sticky=\"nsew\")\n",
    "\n",
    "# dispaly image frame\n",
    "imageDisplayFrame = tk.Frame(imageFrame, bg=\"white\", relief=\"sunken\", bd=1,\n",
    "                             width=200, height=150)\n",
    "imageDisplayFrame.pack(pady=2, padx=10)\n",
    "imageDisplayFrame.pack_propagate(False)\n",
    "\n",
    "imageCanvas = tk.Canvas(imageDisplayFrame, bg=\"white\", highlightthickness=0)\n",
    "imageCanvas.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# image placeholder\n",
    "imageLabel = tk.Label(imageCanvas, text=\"Algorithm\\nImage\",\n",
    "                      bg=\"white\", fg=\"#666\", font=(\"Arial\", 10))\n",
    "imageLabel.pack(expand=True)\n",
    "\n",
    "# next step button\n",
    "nextStepAlgorithms = tk.Button(imageFrame, text=\"Next Step\",\n",
    "                               bg=\"#374451\", fg=\"white\", font=(\"Arial\", 12, \"bold\"),\n",
    "                               width=15, height=2, relief=\"raised\", bd=2)\n",
    "nextStepAlgorithms.pack(pady=5)\n",
    "nextStepAlgorithms.config(state=tk.DISABLED)\n",
    "\n",
    "# initialize description text area\n",
    "initial_message = \"\"\"=== CLUSTERING ALGORITHMS ===\n",
    "\n",
    "Select an algorithm type above to view available algorithms and their descriptions.\n",
    "\n",
    "Types available:\n",
    "• Partitioning: K-Means, K-Medoids\n",
    "• Hierarchical: AGNES, DIANA  \n",
    "• Density-based: DBSCAN\n",
    "\n",
    "Each type has different characteristics and use cases.\"\"\"\n",
    "\n",
    "# insert initial message\n",
    "typeDescText.insert(tk.END, initial_message)\n",
    "typeDescText.config(state=tk.DISABLED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439cbf8",
   "metadata": {},
   "source": [
    "##### 1 - e algorithms frame logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28307707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic functions & variables for algorithms frame\n",
    "current_algorithm_type = None\n",
    "selected_algorithm = None\n",
    "\n",
    "# algorithms frame functions\n",
    "# 1 - main functions\n",
    "\n",
    "# clear algorithms list function\n",
    "def clear_algorithms_list():\n",
    "    for widget in algorithmsListFrame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "# reset algorithms type buttons styles function\n",
    "def reset_type_buttons():\n",
    "    partitioningBtn.config(bg=\"#374451\")\n",
    "    hierarchicalBtn.config(bg=\"#374451\")\n",
    "    densityBtn.config(bg=\"#374451\")\n",
    "\n",
    "# display algorithm type info function\n",
    "def display_algorithm_info(algo_type):\n",
    "    global current_algorithm_type, selected_algorithm\n",
    "    current_algorithm_type = algo_type\n",
    "    selected_algorithm = None\n",
    "\n",
    "    # 1 - display de l'image\n",
    "\n",
    "    imageCanvas.delete(\"all\")\n",
    "\n",
    "    # get image url\n",
    "    image_url = algorithms[current_algorithm_type]['image']\n",
    "\n",
    "    # load image\n",
    "    photo = load_image_from_url(image_url)\n",
    "\n",
    "    if photo:\n",
    "        imageLabel.config(image=photo, text=\"\")\n",
    "        imageLabel.image = photo  # Garder une référence pour éviter le garbage collection\n",
    "    else:\n",
    "        imageLabel.config(image=\"\", text=f\"{current_algorithm_type}\\nImage\\nLoading Error\",\n",
    "                          font=(\"Arial\", 9), fg=\"#ff4444\")\n",
    "\n",
    "    typeDescText.config(state=tk.NORMAL)\n",
    "    typeDescText.delete(1.0, tk.END)\n",
    "\n",
    "    # 2 - update description text area\n",
    "    type_info = algorithms[algo_type]\n",
    "    description = f\"{algo_type.upper()} algorithms\\n\\n\"\n",
    "    description += f\"{type_info['description']}\\n\"\n",
    "    description += \"Available algorithms:\\n\\n\"\n",
    "\n",
    "    for algo_name in type_info['algorithms'].keys():\n",
    "        description += f\"• {algo_name}\\n\"\n",
    "\n",
    "    typeDescText.insert(tk.END, description)\n",
    "    typeDescText.config(state=tk.DISABLED)\n",
    "\n",
    "    # clean and recreate algorithms list (for the appropriate algorithm type)\n",
    "    clear_algorithms_list()\n",
    "    create_algorithm_buttons(algo_type)\n",
    "\n",
    "    # disable next step button\n",
    "    nextStepAlgorithms.config(state=tk.DISABLED)\n",
    "    nextStepAlgorithms.config(bg=\"#374451\")\n",
    "\n",
    "\n",
    "# dynamic create algorithm buttons function\n",
    "def create_algorithm_buttons(algo_type):\n",
    "    algorithms_names = algorithms[algo_type]['algorithms']\n",
    "\n",
    "    # grid frame for algorithms\n",
    "    gridFrame = tk.Frame(algorithmsListFrame, bg=\"white\")\n",
    "    gridFrame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "\n",
    "    # grid configuration\n",
    "    gridFrame.grid_columnconfigure(0, weight=1)\n",
    "    gridFrame.grid_columnconfigure(1, weight=1)\n",
    "\n",
    "    algorithm_keys = list(algorithms_names.keys())\n",
    "\n",
    "    # create buttons for each algorithm\n",
    "    for i, algo_name in enumerate(algorithm_keys):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "\n",
    "        # algorithm main frame\n",
    "        algoMainFrame = tk.Frame(gridFrame, bg=\"#f9f9f9\", relief=\"solid\", bd=1)\n",
    "        algoMainFrame.grid(row=row, column=col, sticky=\"nsew\", padx=3, pady=3)\n",
    "\n",
    "        # grid configuration for algo main frame\n",
    "        algoMainFrame.grid_rowconfigure(0, weight=0)  \n",
    "        algoMainFrame.grid_rowconfigure(1, weight=0)  \n",
    "        algoMainFrame.grid_rowconfigure(2, weight=1)  \n",
    "        algoMainFrame.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "        # algorithm name \n",
    "        algoNameLabel = tk.Label(algoMainFrame, text=f\"🔹 {algo_name}\",\n",
    "                                 bg=\"#f9f9f9\", fg=\"#24367E\",\n",
    "                                 font=(\"Arial\", 11, \"bold\"))\n",
    "        algoNameLabel.grid(row=0, column=0, pady=(8, 2), sticky=\"ew\")\n",
    "\n",
    "        # select algorithm button\n",
    "        selectBtn = tk.Button(algoMainFrame, text=f\"✅ Select\",\n",
    "                              bg=\"#7b9fc2\", fg=\"white\", font=(\"Arial\", 9, \"bold\"),\n",
    "                              width=15, height=1, relief=\"raised\", bd=2,\n",
    "                              cursor=\"hand2\",\n",
    "                              command=lambda name=algo_name: select_algorithm(name))\n",
    "        selectBtn.grid(row=2, column=0, pady=(0, 8), padx=10, sticky=\"ew\")\n",
    "\n",
    "        gridFrame.grid_rowconfigure(row, weight=1)\n",
    "\n",
    "\n",
    "# load image from url function\n",
    "def load_image_from_url(url, size=(180, 140)):\n",
    "\n",
    "    try:\n",
    "        # download image\n",
    "        response = requests.get(url, timeout=2)\n",
    "        response.raise_for_status()\n",
    "\n",
    "       \n",
    "        image = Image.open(BytesIO(response.content))\n",
    "\n",
    "        image = image.resize(size, Image.Resampling.LANCZOS)\n",
    "\n",
    "        # convet image to PhotoImage\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        return photo\n",
    "    except Exception as e:\n",
    "        print(f\"loading image error : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# algorithm selection function\n",
    "def select_algorithm(algo_name):\n",
    "    global selected_algorithm\n",
    "    selected_algorithm = algo_name\n",
    "\n",
    "    # enable next step button after alogrithm selection\n",
    "    nextStepAlgorithms.config(state=tk.NORMAL)\n",
    "    nextStepAlgorithms.config(bg=\"#24367E\")\n",
    "    nextStepAlgorithms.config(cursor=\"hand2\")\n",
    "\n",
    "    # update selection styles\n",
    "    update_algorithm_selection(algo_name)\n",
    "\n",
    "# update algorithm selection styles function\n",
    "def update_algorithm_selection(selected_name):\n",
    "    \n",
    "    gridFrame = None\n",
    "    for widget in algorithmsListFrame.winfo_children():\n",
    "        if isinstance(widget, tk.Frame) and len(widget.winfo_children()) > 1:\n",
    "            gridFrame = widget\n",
    "            break\n",
    "\n",
    "    if not gridFrame:\n",
    "        return\n",
    "\n",
    "    # iterate through algorithm frames to update styles\n",
    "    for algoFrame in gridFrame.winfo_children():\n",
    "        if isinstance(algoFrame, tk.Frame):\n",
    "            # locate algorithm name label\n",
    "            nameLabel = algoFrame.winfo_children()[0]\n",
    "            current_name = nameLabel.cget(\"text\").replace(\"🔹 \", \"\")\n",
    "\n",
    "            if current_name == selected_name:\n",
    "                # style for selected algorithm\n",
    "                algoFrame.config(bg=\"#d4edda\", relief=\"solid\", bd=2)\n",
    "                nameLabel.config(bg=\"#d4edda\")\n",
    "\n",
    "                # find and update the button\n",
    "                for child in algoFrame.winfo_children():\n",
    "                    if isinstance(child, tk.Button):\n",
    "                        child.config(\n",
    "                            text=f\"✅ {selected_name} (Selected)\", bg=\"#28a745\")\n",
    "            else:\n",
    "                # default style (non-selected algorithm)\n",
    "                algoFrame.config(bg=\"#f9f9f9\", relief=\"solid\", bd=1)\n",
    "                nameLabel.config(bg=\"#f9f9f9\")\n",
    "\n",
    "                # reset button style\n",
    "                for child in algoFrame.winfo_children():\n",
    "                    if isinstance(child, tk.Button):\n",
    "                        child.config(text=\"✅ Select\", bg=\"#7b9fc2\")\n",
    "\n",
    "\n",
    "# 2- functions to display algorithm types\n",
    "\n",
    "# 2- 1) partitioning algorithms\n",
    "# display partitioning algorithms function\n",
    "def show_partitioning_algorithms():\n",
    "    reset_type_buttons()\n",
    "    partitioningBtn.config(bg=\"#24367E\")\n",
    "    display_algorithm_info(\"Partitioning\")\n",
    "\n",
    "# assign function to partitioning button\n",
    "partitioningBtn.config(command=show_partitioning_algorithms)\n",
    "\n",
    "# 2- 2) hierarchical algorithms\n",
    "# display hierarchical algorithms function\n",
    "def show_hierarchical_algorithms():\n",
    "    reset_type_buttons()\n",
    "    hierarchicalBtn.config(bg=\"#24367E\")\n",
    "    display_algorithm_info(\"Hierarchical\")\n",
    "\n",
    "# assign function to hierarchical button\n",
    "hierarchicalBtn.config(command=show_hierarchical_algorithms)\n",
    "\n",
    "# 2- 3) density-based algorithms\n",
    "# display density-based algorithms function\n",
    "def show_density_algorithms():\n",
    "    reset_type_buttons()\n",
    "    densityBtn.config(bg=\"#24367E\")\n",
    "    display_algorithm_info(\"Density-based\")\n",
    "\n",
    "# assign function to density-based button\n",
    "densityBtn.config(command=show_density_algorithms)\n",
    "\n",
    "# next step button\n",
    "nextStepAlgorithms.config(command=incrementStep)\n",
    "\n",
    "# default display partitioning algorithms\n",
    "show_partitioning_algorithms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b45a6d",
   "metadata": {},
   "source": [
    "#### 1 -f Vizualization Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d2431",
   "metadata": {},
   "source": [
    "##### 1 - f Visualization frame design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7396009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import ttk\n",
    "\n",
    "# visulaization frame\n",
    "visualizationFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "\n",
    "visualizationTitleLabel = tk.Label(visualizationFrame, text=\"Algorithm Visualization\",\n",
    "                                   bg=\"#f0f0f0\", fg=\"#24367E\", font=(\"Arial\", 13, \"bold\"))\n",
    "visualizationTitleLabel.pack(pady=2)\n",
    "\n",
    "# main content frame\n",
    "mainVisualizationFrame = tk.Frame(visualizationFrame, bg=\"#f0f0f0\")\n",
    "mainVisualizationFrame.pack(fill=tk.BOTH, expand=True, padx=10, pady=2)\n",
    "\n",
    "# main content frame grid configuration\n",
    "mainVisualizationFrame.grid_columnconfigure(0, weight=3)  \n",
    "mainVisualizationFrame.grid_columnconfigure(1, weight=1)  \n",
    "mainVisualizationFrame.grid_rowconfigure(0, weight=0)     \n",
    "mainVisualizationFrame.grid_rowconfigure(\n",
    "    1, weight=1)    \n",
    "\n",
    "\n",
    "# top grid (parameters + apply algorithm button)\n",
    "\n",
    "# parametres section\n",
    "parametersFrame = tk.Frame(mainVisualizationFrame, bd=2)\n",
    "parametersFrame.grid(row=0, column=0, sticky=\"ew\", padx=(0, 10), pady=(0, 2))\n",
    "\n",
    "\n",
    "paramsTitleLabel = tk.Label(parametersFrame, text=\"Algorithm Parameters\",\n",
    "                            fg=\"#24367E\", font=(\"Arial\", 12, \"bold\"))\n",
    "paramsTitleLabel.pack(pady=5)\n",
    "\n",
    "# parametres grid frame\n",
    "paramsGridFrame = tk.Frame(parametersFrame)\n",
    "paramsGridFrame.pack(fill=tk.X, padx=15, pady=10)\n",
    "\n",
    "# three columns grid for parameters\n",
    "paramsGridFrame.grid_columnconfigure(0, weight=1)\n",
    "paramsGridFrame.grid_columnconfigure(1, weight=1)\n",
    "paramsGridFrame.grid_columnconfigure(2, weight=1)\n",
    "\n",
    "# apply button frame\n",
    "applyButtonFrame = tk.Frame(mainVisualizationFrame, bd=2)\n",
    "applyButtonFrame.grid(row=0, column=1, sticky=\"nsew\", pady=(0, 2))\n",
    "\n",
    "# apply algorithm button\n",
    "applyAlgorithmBtn = tk.Button(applyButtonFrame, text=\"Apply Algorithm\",\n",
    "                              bg=\"#24367E\", fg=\"white\", font=(\"Arial\", 13, \"bold\"),\n",
    "                              width=18, height=2, relief=\"raised\", bd=2)\n",
    "applyAlgorithmBtn.pack(pady=20)\n",
    "\n",
    "# bottom grid (visualization + results)\n",
    "contentFrame = tk.Frame(mainVisualizationFrame, bg=\"#f0f0f0\")\n",
    "contentFrame.grid(row=1, column=0, columnspan=2, sticky=\"nsew\")\n",
    "\n",
    "# grid partitioning\n",
    "contentFrame.grid_columnconfigure(0, weight=3)\n",
    "contentFrame.grid_columnconfigure(1, weight=1)\n",
    "contentFrame.grid_rowconfigure(0, weight=1)\n",
    "\n",
    "# visualization area\n",
    "visualizationFrame_area = tk.Frame(\n",
    "    contentFrame, bg=\"white\", relief=\"sunken\", bd=2)\n",
    "visualizationFrame_area.grid(row=0, column=0, sticky=\"nsew\", padx=(0, 5))\n",
    "\n",
    "# visualization title\n",
    "vizTitleLabel = tk.Label(visualizationFrame_area, text=\"Clustering Visualization\",\n",
    "                         bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 12, \"bold\"))\n",
    "vizTitleLabel.pack(pady=3)\n",
    "\n",
    "# Plot frame\n",
    "vizPlotFrame = tk.Frame(visualizationFrame_area, bg=\"white\")\n",
    "vizPlotFrame.pack(fill=tk.BOTH, expand=True, padx=8, pady=3)\n",
    "\n",
    "# result part\n",
    "resultsColumn = tk.Frame(contentFrame, bg=\"#f8f9fa\", relief=\"raised\", bd=2)\n",
    "resultsColumn.grid(row=0, column=1, sticky=\"nsew\", padx=(5, 0))\n",
    "\n",
    "\n",
    "resultsTitleLabel = tk.Label(resultsColumn, text=\"Results\",\n",
    "                             bg=\"#f8f9fa\", fg=\"#24367E\", font=(\"Arial\", 12, \"bold\"))\n",
    "resultsTitleLabel.pack(pady=8)\n",
    "\n",
    "# results display area\n",
    "resultsDisplayFrame = tk.Frame(\n",
    "    resultsColumn, bg=\"white\", relief=\"sunken\", bd=1)\n",
    "\n",
    "resultsDisplayFrame.pack(fill=tk.BOTH, expand=True, padx=8, pady=3)\n",
    "\n",
    "resultsTextArea = scrolledtext.ScrolledText(resultsDisplayFrame, height=12, width=22,\n",
    "                                            font=(\"Courier\", 8), bg=\"white\", fg=\"#333333\",\n",
    "                                            wrap=\"word\", relief=\"flat\", bd=0)\n",
    "resultsTextArea.pack(fill=tk.BOTH, expand=True, padx=3, pady=3)\n",
    "\n",
    "# navigation buttons frame\n",
    "navigationButtonsFrame = tk.Frame(resultsColumn, bg=\"#f8f9fa\")\n",
    "navigationButtonsFrame.pack(pady=8)\n",
    "\n",
    "# previous Step button\n",
    "previousStepVisualization = tk.Button(navigationButtonsFrame, text=\"Previous Step\",\n",
    "                                      bg=\"#1e507d\", fg=\"white\", font=(\"Arial\", 10, \"bold\"),\n",
    "                                      width=12, height=2, relief=\"raised\", bd=2)\n",
    "previousStepVisualization.pack(side=tk.LEFT, padx=(0, 5))\n",
    "\n",
    "# next Step button\n",
    "nextStepVisualization = tk.Button(navigationButtonsFrame, text=\"Next Step\",\n",
    "                                  bg=\"#374451\", fg=\"white\", font=(\"Arial\", 10, \"bold\"),\n",
    "                                  width=12, height=2, relief=\"raised\", bd=2)\n",
    "nextStepVisualization.pack(side=tk.LEFT, padx=(5, 0))\n",
    "nextStepVisualization.config(state=tk.DISABLED)\n",
    "\n",
    "# initial results message\n",
    "resultsTextArea.insert(\n",
    "    tk.END, \"Results will appear here after applying the algorithm...\\n\\n\")\n",
    "resultsTextArea.insert(tk.END, \"Cluster Information:\\n\")\n",
    "resultsTextArea.insert(tk.END, \"- Number of clusters: -\\n\")\n",
    "resultsTextArea.insert(tk.END, \"- Total data points: -\\n\")\n",
    "resultsTextArea.insert(tk.END, \"- Algorithm status: Waiting\\n\")\n",
    "\n",
    "# dynamic parameter inputs creation\n",
    "def create_parameter_inputs():\n",
    "    global selected_algorithm, current_algorithm_type\n",
    "\n",
    "    for widget in paramsGridFrame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    if not selected_algorithm or not current_algorithm_type:\n",
    "        no_algo_label = tk.Label(paramsGridFrame, text=\"No algorithm selected\",\n",
    "                                 bg=\"white\", fg=\"#666\", font=(\"Arial\", 10))\n",
    "        no_algo_label.grid(row=0, column=1, pady=10)\n",
    "        return\n",
    "\n",
    "    # update title with selected algorithm\n",
    "    visualizationTitleLabel.config(text=f\"{selected_algorithm} Visualization\")\n",
    "\n",
    "    # get parameters for selected algorithm\n",
    "    algo_params = algorithms[current_algorithm_type]['algorithms'][selected_algorithm]['parameters']\n",
    "\n",
    "    # create parameter inputs\n",
    "    for i, param in enumerate(algo_params):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "\n",
    "        # parameter frame\n",
    "        paramFrame = tk.Frame(paramsGridFrame, bg=\"white\",\n",
    "                              relief=\"groove\", bd=1)\n",
    "        paramFrame.grid(row=row, column=col, padx=5, pady=5, sticky=\"ew\")\n",
    "\n",
    "        # parameter label\n",
    "        paramLabel = tk.Label(paramFrame, text=param.replace('_', ' ').title(),\n",
    "                              bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 9, \"bold\"))\n",
    "        paramLabel.pack(pady=(5, 2))\n",
    "\n",
    "        # parameter input\n",
    "        if param == 'n_clusters':\n",
    "            # use optimal K from cluster analysis\n",
    "            global optimal_k_global\n",
    "            default_value = optimal_k_global if optimal_k_global else 3\n",
    "\n",
    "            valueLabel = tk.Label(paramFrame, text=str(default_value),\n",
    "                                  bg=\"#e9ecef\", fg=\"#24367E\", font=(\"Arial\", 10, \"bold\"),\n",
    "                                  relief=\"sunken\", bd=1, width=8)\n",
    "            valueLabel.pack(pady=(0, 5))\n",
    "\n",
    "        elif param == 'distance_metric':\n",
    "            # dropdown for distance metric selection\n",
    "            metricCombo = ttk.Combobox(paramFrame, values=[\"euclidean\", \"manhattan\"],\n",
    "                                       state=\"readonly\", width=8, font=(\"Arial\", 9))\n",
    "            metricCombo.set(\"euclidean\")\n",
    "            metricCombo.pack(pady=(0, 5))\n",
    "\n",
    "        elif param == 'linkage':\n",
    "            # dropdown for linkage selection\n",
    "            linkageCombo = ttk.Combobox(paramFrame, values=[\"complete\", \"average\", \"single\"],\n",
    "                                        state=\"readonly\", width=8, font=(\"Arial\", 9))\n",
    "            linkageCombo.set(\"single\")\n",
    "            linkageCombo.pack(pady=(0, 5))\n",
    "\n",
    "        else:\n",
    "            # regular input field\n",
    "            paramEntry = tk.Entry(paramFrame, width=10, font=(\"Arial\", 9),\n",
    "                                  justify=\"center\", relief=\"sunken\", bd=1)\n",
    "            paramEntry.pack(pady=(0, 5))\n",
    "\n",
    "            # set default values based on parameter type\n",
    "            if 'eps' in param:\n",
    "                paramEntry.insert(0, \"0.5\")\n",
    "            elif 'min_samples' in param:\n",
    "                paramEntry.insert(0, \"5\")\n",
    "            elif 'max_iter' in param:\n",
    "                paramEntry.insert(0, \"150\")\n",
    "\n",
    "\n",
    "# reset visualization frame function\n",
    "def format_visualization_frame():\n",
    "    global selected_algorithm, current_algorithm_type, clustering_results\n",
    "\n",
    "    visualizationTitleLabel.config(text=\"Algorithm Visualization\")\n",
    "\n",
    "    resultsTextArea.delete(1.0, tk.END)\n",
    "\n",
    "    # reset initial message\n",
    "    resultsTextArea.insert(\n",
    "        tk.END, \"Results will appear here after applying the algorithm...\\n\\n\")\n",
    "    resultsTextArea.insert(tk.END, \"Cluster Information:\\n\")\n",
    "    resultsTextArea.insert(tk.END, \"- Number of clusters: -\\n\")\n",
    "    resultsTextArea.insert(tk.END, \"- Total data points: -\\n\")\n",
    "    resultsTextArea.insert(tk.END, \"- Algorithm status: Waiting\\n\")\n",
    "\n",
    "    # clear visualization plot\n",
    "    for widget in vizPlotFrame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    # reset next step button states\n",
    "    nextStepVisualization.config(state=tk.DISABLED)\n",
    "    nextStepVisualization.config(bg=\"#374451\")\n",
    "\n",
    "    # clear clustering results\n",
    "    clustering_results = None\n",
    "\n",
    "\n",
    "# previous step button action\n",
    "previousStepVisualization.config(command=decrementStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de34bb2",
   "metadata": {},
   "source": [
    "##### 1 - f visualization frame logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad66f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage as scipy_linkage, fcluster\n",
    "from scipy.spatial.distance import pdist , cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# global variables to store clustering results\n",
    "clustering_results = None\n",
    "params = {}\n",
    "\n",
    "\n",
    "# function to get parameter values from GUI\n",
    "def get_parameter_values():\n",
    "    \n",
    "    global params;  \n",
    "\n",
    "    for widget in paramsGridFrame.winfo_children():\n",
    "        if isinstance(widget, tk.Frame):\n",
    "            label = widget.winfo_children()[0]\n",
    "            param_name = label.cget(\"text\").lower().replace(\" \", \"_\")\n",
    "\n",
    "            if param_name == \"n_clusters\":\n",
    "                value_widget = widget.winfo_children()[1]\n",
    "                params[\"n_clusters\"] = int(value_widget.cget(\"text\"))\n",
    "\n",
    "            elif param_name == \"distance_metric\":\n",
    "                combo_widget = widget.winfo_children()[1]\n",
    "                params[\"distance_metric\"] = combo_widget.get()\n",
    "\n",
    "            elif param_name == \"linkage\":\n",
    "                combo_widget = widget.winfo_children()[1]\n",
    "                params[\"linkage\"] = combo_widget.get()\n",
    "\n",
    "            elif param_name in [\"max_iter\", \"eps\", \"min_samples\"]:\n",
    "                entry_widget = widget.winfo_children()[1]\n",
    "                try:\n",
    "                    if param_name == \"eps\":\n",
    "                        params[param_name] = float(entry_widget.get())\n",
    "                    else:\n",
    "                        params[param_name] = int(entry_widget.get())\n",
    "                except ValueError:\n",
    "                    if param_name == \"max_iter\":\n",
    "                        params[param_name] = 300\n",
    "                    elif param_name == \"eps\":\n",
    "                        params[param_name] = 0.5\n",
    "                    elif param_name == \"min_samples\":\n",
    "                        params[param_name] = 5\n",
    "\n",
    "    return params\n",
    "\n",
    "# prepare data for clustering function\n",
    "def prepare_data_for_clustering():\n",
    "    \n",
    "    global dataSet_data\n",
    "\n",
    "    if dataSet_data is None:\n",
    "        return None, \"No dataset loaded\"\n",
    "\n",
    "    last_column = dataSet_data.columns[-1]\n",
    "    features = dataSet_data.drop(last_column, axis=1)\n",
    "    numeric_features = features.select_dtypes(include=[np.number])\n",
    "\n",
    "    if len(numeric_features.columns) == 0:\n",
    "        return None, \"No numeric features found\"\n",
    "\n",
    "    return numeric_features.values, None\n",
    "\n",
    "\n",
    "# 1  Clustering algorithm implementations\n",
    "\n",
    "# 1 - 1) Hierarchical Clustering: AGNES and DIANA\n",
    "# AGNES clustering function\n",
    "def agnes_clustering(data, n_clusters, linkage_method, distance_metric):\n",
    "    try:\n",
    "\n",
    "        distance_mapping = {\n",
    "            'euclidean': 'euclidean',\n",
    "            'manhattan': 'cityblock',\n",
    "        }\n",
    "\n",
    "        scipy_distance = distance_mapping.get(distance_metric, 'euclidean')\n",
    "\n",
    "        distances = pdist(data, metric=scipy_distance)\n",
    "\n",
    "        linkage_matrix = scipy_linkage(distances, method=linkage_method)\n",
    "\n",
    "        labels = fcluster(linkage_matrix, n_clusters, criterion='maxclust')\n",
    "\n",
    "        return {\n",
    "            'labels': labels - 1,  \n",
    "            'linkage_matrix': linkage_matrix,\n",
    "            'n_clusters': n_clusters,\n",
    "            'algorithm': 'AGNES',\n",
    "            'linkage_method': linkage_method,\n",
    "            'distance_metric': distance_metric,\n",
    "            'n_points': len(data)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# DIANA clustering function\n",
    "def diana_clustering(data, n_clusters, distance_metric):\n",
    "    try:\n",
    "        distance_mapping = {\n",
    "            'euclidean': 'euclidean',\n",
    "            'manhattan': 'cityblock',\n",
    "        }\n",
    "\n",
    "        scipy_distance = distance_mapping.get(distance_metric, 'euclidean')\n",
    "\n",
    "        distances = pdist(data, metric=scipy_distance)\n",
    "\n",
    "        linkage_matrix = scipy_linkage(distances, method='complete')\n",
    "\n",
    "        labels = fcluster(linkage_matrix, n_clusters, criterion='maxclust')\n",
    "\n",
    "        return {\n",
    "            'labels': labels - 1,\n",
    "            'linkage_matrix': linkage_matrix,\n",
    "            'n_clusters': n_clusters,\n",
    "            'algorithm': 'DIANA',\n",
    "            'distance_metric': distance_metric,\n",
    "            'n_points': len(data)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "\n",
    "# 1 - 2) Partitioning Clustering: K-Means and K-Medoids\n",
    "# K-Means clustering function \n",
    "def kmeans_clustering(data, n_clusters, distance_metric, max_iter):\n",
    "    try:\n",
    "        from sklearn.cluster import KMeans\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iter,\n",
    "                        random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(data)\n",
    "\n",
    "        return {\n",
    "            'labels': labels,\n",
    "            'centers': kmeans.cluster_centers_,\n",
    "            'n_clusters': n_clusters,\n",
    "            'algorithm': 'K-Means',\n",
    "            'distance_metric': distance_metric,\n",
    "            'max_iter': max_iter,\n",
    "            'n_points': len(data),\n",
    "            'inertia': kmeans.inertia_\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# K-Medoids clustering function\n",
    "def kmedoids_clustering(data, n_clusters, distance_metric, max_iter):\n",
    "   \n",
    "    try:\n",
    "        np.random.seed(42)  \n",
    "        \n",
    "        n_samples = data.shape[0]\n",
    "        \n",
    "        metric_mapping = {\n",
    "            'euclidean': 'euclidean',\n",
    "            'manhattan': 'cityblock'\n",
    "        }\n",
    "        \n",
    "        metric = metric_mapping.get(distance_metric, 'euclidean')\n",
    "        \n",
    "        medoid_indices = np.random.choice(n_samples, n_clusters, replace=False)\n",
    "        medoids = data[medoid_indices]\n",
    "        \n",
    "        for iteration in range(max_iter):\n",
    "            distances = cdist(data, medoids, metric=metric)\n",
    "            labels = np.argmin(distances, axis=1)\n",
    "            \n",
    "            new_medoid_indices = []\n",
    "            cost_improved = False\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                cluster_points = data[labels == cluster_id]\n",
    "                cluster_indices = np.where(labels == cluster_id)[0]\n",
    "                \n",
    "                if len(cluster_points) == 0:\n",
    "                    new_medoid_indices.append(medoid_indices[cluster_id])\n",
    "                    continue\n",
    "                \n",
    "                current_medoid_idx = medoid_indices[cluster_id]\n",
    "                current_cost = np.sum(cdist([data[current_medoid_idx]], cluster_points, metric=metric))\n",
    "                \n",
    "                best_medoid_idx = current_medoid_idx\n",
    "                best_cost = current_cost\n",
    "                \n",
    "                for point_idx in cluster_indices:\n",
    "                    cost = np.sum(cdist([data[point_idx]], cluster_points, metric=metric))\n",
    "                    if cost < best_cost:\n",
    "                        best_cost = cost\n",
    "                        best_medoid_idx = point_idx\n",
    "                        cost_improved = True\n",
    "                \n",
    "                new_medoid_indices.append(best_medoid_idx)\n",
    "            \n",
    "            medoid_indices = np.array(new_medoid_indices)\n",
    "            new_medoids = data[medoid_indices]\n",
    "            \n",
    "            if not cost_improved or np.array_equal(medoids, new_medoids):\n",
    "                break\n",
    "                \n",
    "            medoids = new_medoids\n",
    "        \n",
    "        distances = cdist(data, medoids, metric=metric)\n",
    "        final_labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        total_inertia = 0\n",
    "        for i, label in enumerate(final_labels):\n",
    "            total_inertia += distances[i, label]\n",
    "        \n",
    "        return {\n",
    "            'labels': final_labels,\n",
    "            'medoids': medoids,\n",
    "            'medoid_indices': medoid_indices,\n",
    "            'n_clusters': n_clusters,\n",
    "            'algorithm': 'K-Medoids',\n",
    "            'distance_metric': distance_metric,\n",
    "            'max_iter': max_iter,\n",
    "            'n_points': len(data),\n",
    "            'inertia': total_inertia,\n",
    "            'iterations_run': iteration + 1\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "\n",
    "# 1 - 3) Density-Based Clustering: DBSCAN\n",
    "# DBSCAN clustering function\n",
    "def dbscan_clustering(data, eps, min_samples):\n",
    "    try:\n",
    "\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(data)\n",
    "        \n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = list(labels).count(-1)\n",
    "        n_core = len(dbscan.core_sample_indices_)\n",
    "        n_border = len(data) - n_core - n_noise\n",
    "        \n",
    "        return {\n",
    "            'labels': labels,\n",
    "            'core_sample_indices': dbscan.core_sample_indices_,\n",
    "            'n_clusters': n_clusters,\n",
    "            'algorithm': 'DBSCAN',\n",
    "            'eps': eps,\n",
    "            'min_samples': min_samples,\n",
    "            'n_points': len(data),\n",
    "            'n_core_points': n_core,\n",
    "            'n_border_points': n_border,\n",
    "            'n_noise_points': n_noise\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "\n",
    "# 2 - visualization functions\n",
    "\n",
    "# 2- 1) scatter plot for partitioning algorithms\n",
    "def plot_scatter_clusters(result):\n",
    "    for widget in vizPlotFrame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    data, _ = prepare_data_for_clustering()\n",
    "    if data is None:\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "    # use first two dimensions for visualization\n",
    "    if data.shape[1] >= 2:\n",
    "        x_data = data[:, 0]\n",
    "        y_data = data[:, 1]\n",
    "    else:\n",
    "        x_data = data[:, 0]\n",
    "        y_data = np.zeros(len(data))\n",
    "\n",
    "    # plot points colored by cluster\n",
    "    scatter = ax.scatter(x_data, y_data, c=result['labels'],\n",
    "                         cmap='viridis', alpha=0.6, s=50)\n",
    "\n",
    "    cmap = plt.cm.viridis\n",
    "    unique_labels = np.unique(result['labels'])\n",
    "    \n",
    "    # plot centers or medoids with cluster colors\n",
    "    if 'centers' in result:\n",
    "        centers = result['centers']\n",
    "        for i, center in enumerate(centers):\n",
    "            if i < len(unique_labels):\n",
    "                cluster_color = cmap(unique_labels[i] / max(unique_labels) if len(unique_labels) > 1 else 0)\n",
    "                ax.scatter(center[0], center[1] if centers.shape[1] > 1 else 0,\n",
    "                          c=[cluster_color], marker='x', s=200, linewidths=3, \n",
    "                          edgecolors='black', label=f'Centroid {i}' if i == 0 else \"\")\n",
    "        \n",
    "        # add legend entry for centroids\n",
    "        if len(centers) > 0:\n",
    "            ax.scatter([], [], c='black', marker='x', s=200, linewidths=3, \n",
    "                      label='Centroids', alpha=0)\n",
    "            \n",
    "    elif 'medoids' in result:\n",
    "        medoids = result['medoids']\n",
    "        for i, medoid in enumerate(medoids):\n",
    "            if i < len(unique_labels):\n",
    "                cluster_color = cmap(unique_labels[i] / max(unique_labels) if len(unique_labels) > 1 else 0)\n",
    "                ax.scatter(medoid[0], medoid[1] if medoids.shape[1] > 1 else 0,\n",
    "                          c=[cluster_color], marker='s', s=200, linewidths=3, \n",
    "                          edgecolors='black', label=f'Medoid {i}' if i == 0 else \"\")\n",
    "        \n",
    "        # add legend entry for medoids\n",
    "        if len(medoids) > 0:\n",
    "            ax.scatter([], [], c='black', marker='s', s=200, linewidths=3, \n",
    "                      label='Medoids', alpha=0)\n",
    "\n",
    "    # set axis labels\n",
    "    if data is not None and dataSet_data is not None:\n",
    "        # get feature column names \n",
    "        feature_columns = dataSet_data.drop(\n",
    "            dataSet_data.columns[-1], axis=1).select_dtypes(include=[np.number]).columns\n",
    "\n",
    "        if len(feature_columns) >= 2:\n",
    "            ax.set_xlabel(feature_columns[0])\n",
    "            ax.set_ylabel(feature_columns[1])\n",
    "        elif len(feature_columns) == 1:\n",
    "            ax.set_xlabel(feature_columns[0])\n",
    "            ax.set_ylabel('Zero')\n",
    "        else:\n",
    "            ax.set_xlabel('Feature 1')\n",
    "            ax.set_ylabel('Feature 2')\n",
    "    else:\n",
    "        ax.set_xlabel('Feature 1')\n",
    "        ax.set_ylabel('Feature 2')\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.colorbar(scatter)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, vizPlotFrame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# 2- 2) DBSCAN clustering plot\n",
    "def plot_dbscan_clusters(result):\n",
    "    for widget in vizPlotFrame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    data, _ = prepare_data_for_clustering()\n",
    "    if data is None:\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "    # use first two dimensions for visualization\n",
    "    if data.shape[1] >= 2:\n",
    "        x_data = data[:, 0]\n",
    "        y_data = data[:, 1]\n",
    "    else:\n",
    "        x_data = data[:, 0]\n",
    "        y_data = np.zeros(len(data))\n",
    "\n",
    "    labels = result['labels']\n",
    "    core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
    "    core_samples_mask[result['core_sample_indices']] = True\n",
    "\n",
    "    # get unique cluster labels (excluding noise)\n",
    "    unique_labels = set(labels)\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_member_mask = (labels == k)\n",
    "\n",
    "        # plot core samples\n",
    "        xy_core = np.column_stack([x_data[class_member_mask & core_samples_mask],\n",
    "                                   y_data[class_member_mask & core_samples_mask]])\n",
    "        if len(xy_core) > 0:\n",
    "            if k == -1:\n",
    "                ax.scatter(xy_core[:, 0], xy_core[:, 1], s=50, c=[col], marker='x',\n",
    "                          alpha=0.8, label='Noise' if k == -1 else f'Core {k}')\n",
    "            else:\n",
    "                ax.scatter(xy_core[:, 0], xy_core[:, 1], s=80, c=[col], marker='o',\n",
    "                          edgecolors='black', linewidths=1, alpha=0.8)\n",
    "\n",
    "        # plot border samples\n",
    "        xy_border = np.column_stack([x_data[class_member_mask & ~core_samples_mask],\n",
    "                                     y_data[class_member_mask & ~core_samples_mask]])\n",
    "        if len(xy_border) > 0 and k != -1:\n",
    "            ax.scatter(xy_border[:, 0], xy_border[:, 1], s=40, c=[col], marker='o',\n",
    "                      alpha=0.6, edgecolors='black', linewidths=0.5)\n",
    "\n",
    "    # create custom legend\n",
    "    ax.scatter([], [], c='black', s=80, marker='o', edgecolors='black', \n",
    "               linewidths=1, label='Core Points', alpha=0)\n",
    "    ax.scatter([], [], c='gray', s=40, marker='o', edgecolors='black', \n",
    "               linewidths=0.5, label='Border Points', alpha=0)\n",
    "    ax.scatter([], [], c='black', s=50, marker='x', \n",
    "               label='Noise Points', alpha=0)\n",
    "\n",
    "    # set axis labels\n",
    "    if data is not None and dataSet_data is not None:\n",
    "        feature_columns = dataSet_data.drop(\n",
    "            dataSet_data.columns[-1], axis=1).select_dtypes(include=[np.number]).columns\n",
    "\n",
    "        if len(feature_columns) >= 2:\n",
    "            ax.set_xlabel(feature_columns[0])\n",
    "            ax.set_ylabel(feature_columns[1])\n",
    "        elif len(feature_columns) == 1:\n",
    "            ax.set_xlabel(feature_columns[0])\n",
    "            ax.set_ylabel('Zero')\n",
    "        else:\n",
    "            ax.set_xlabel('Feature 1')\n",
    "            ax.set_ylabel('Feature 2')\n",
    "    else:\n",
    "        ax.set_xlabel('Feature 1')\n",
    "        ax.set_ylabel('Feature 2')\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_title(f'DBSCAN Clustering (eps={result[\"eps\"]}, min_samples={result[\"min_samples\"]})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, vizPlotFrame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# 2- 3) Dendrogram for hierarchical algorithms\n",
    "def plot_dendrogram(result):\n",
    "    for widget in vizPlotFrame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    # plot dendrogram\n",
    "    dend = dendrogram(result['linkage_matrix'], ax=ax,\n",
    "                      truncate_mode='lastp', p=30,\n",
    "                      show_leaf_counts=True)\n",
    "\n",
    "    ax.set_xlabel('Sample Index or Cluster Size')\n",
    "    ax.set_ylabel('Distance')\n",
    "\n",
    "    # add horizontal line at cut level\n",
    "    if 'n_clusters' in result:\n",
    "        # calculate cut height for n_clusters\n",
    "        cut_height = result['linkage_matrix'][-(result['n_clusters']-1), 2]\n",
    "        ax.axhline(y=cut_height, color='red', linestyle='--',\n",
    "                   label=f'Cut for {result[\"n_clusters\"]} clusters')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, vizPlotFrame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "\n",
    "\n",
    "#  update results display function\n",
    "def update_results_display(result):\n",
    "    resultsTextArea.delete(1.0, tk.END)\n",
    "\n",
    "    if 'error' in result:\n",
    "        resultsTextArea.insert(tk.END, f\"Error in {selected_algorithm}:\\n\")\n",
    "        resultsTextArea.insert(tk.END, f\"{result['error']}\\n\\n\")\n",
    "        return\n",
    "\n",
    "    resultsTextArea.insert(\n",
    "        tk.END, f\"{result['algorithm']} Clustering Results\\n\")\n",
    "    resultsTextArea.insert(tk.END, \"=\" * 25 + \"\\n\\n\")\n",
    "\n",
    "    resultsTextArea.insert(tk.END, f\"Algorithm: {result['algorithm']}\\n\")\n",
    "    \n",
    "    if 'n_clusters' in result:\n",
    "        resultsTextArea.insert(\n",
    "            tk.END, f\"Number of clusters: {result['n_clusters']}\\n\")\n",
    "    \n",
    "    resultsTextArea.insert(\n",
    "        tk.END, f\"Total data points: {result['n_points']}\\n\")\n",
    "    \n",
    "    if 'distance_metric' in result:\n",
    "        resultsTextArea.insert(\n",
    "            tk.END, f\"Distance metric: {result['distance_metric']}\\n\")\n",
    "\n",
    "    if 'linkage_method' in result:\n",
    "        resultsTextArea.insert(\n",
    "            tk.END, f\"Linkage method: {result['linkage_method']}\\n\")\n",
    "\n",
    "    if 'max_iter' in result:\n",
    "        resultsTextArea.insert(\n",
    "            tk.END, f\"Max iterations: {result['max_iter']}\\n\")\n",
    "\n",
    "    if 'eps' in result:\n",
    "        resultsTextArea.insert(tk.END, f\"Epsilon (eps): {result['eps']}\\n\")\n",
    "        resultsTextArea.insert(tk.END, f\"Min samples: {result['min_samples']}\\n\")\n",
    "\n",
    "    if 'inertia' in result:\n",
    "        resultsTextArea.insert(\n",
    "            tk.END, f\"Inertia/WCSS: {result['inertia']:.2f}\\n\")\n",
    "\n",
    "    # DBSCAN specific information\n",
    "    if result['algorithm'] == 'DBSCAN':\n",
    "        resultsTextArea.insert(tk.END, f\"\\nPoint Classification:\\n\")\n",
    "        resultsTextArea.insert(tk.END, \"-\" * 20 + \"\\n\")\n",
    "        resultsTextArea.insert(tk.END, f\"Core points: {result['n_core_points']}\\n\")\n",
    "        resultsTextArea.insert(tk.END, f\"Border points: {result['n_border_points']}\\n\")\n",
    "        resultsTextArea.insert(tk.END, f\"Noise points: {result['n_noise_points']}\\n\")\n",
    "\n",
    "    resultsTextArea.insert(tk.END, \"\\nCluster Distribution:\\n\")\n",
    "    resultsTextArea.insert(tk.END, \"-\" * 20 + \"\\n\")\n",
    "\n",
    "    unique_labels, counts = np.unique(result['labels'], return_counts=True)\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        if label == -1:\n",
    "            resultsTextArea.insert(tk.END, f\"Noise: {count} points\\n\")\n",
    "        else:\n",
    "            resultsTextArea.insert(tk.END, f\"Cluster {label}: {count} points\\n\")\n",
    "\n",
    "    resultsTextArea.insert(\n",
    "        tk.END, f\"\\nStatus: Clustering completed successfully\\n\")\n",
    "\n",
    "    if result['algorithm'] in ['K-Means', 'K-Medoids']:\n",
    "        resultsTextArea.insert(tk.END, \"Scatter plot displayed on the left\\n\")\n",
    "        vizTitleLabel.config(text=f\"{selected_algorithm} Clusters\")\n",
    "    elif result['algorithm'] == 'DBSCAN':\n",
    "        resultsTextArea.insert(tk.END, \"DBSCAN visualization displayed on the left\\n\")\n",
    "        vizTitleLabel.config(text=f\"{selected_algorithm} Clusters\")\n",
    "    else:\n",
    "        resultsTextArea.insert(tk.END, \"Dendrogram displayed on the left\\n\")\n",
    "        vizTitleLabel.config(text=f\"{selected_algorithm} Dendrogram\")\n",
    "\n",
    "\n",
    "# 3 - functions to apply algorithms\n",
    "\n",
    "# 3 - 1) partitioning algorithms\n",
    "def apply_partitioning_algorithm():\n",
    "    global clustering_results, selected_algorithm, current_algorithm_type\n",
    "\n",
    "    if not selected_algorithm or current_algorithm_type != \"Partitioning\":\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(\n",
    "            tk.END, \"Please select a partitioning algorithm first\")\n",
    "        return\n",
    "\n",
    "    data, error = prepare_data_for_clustering()\n",
    "    if error:\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(tk.END, f\"Data preparation error: {error}\")\n",
    "        return\n",
    "\n",
    "    params = get_parameter_values()\n",
    "\n",
    "    if selected_algorithm == \"K-Means\":\n",
    "        result = kmeans_clustering(\n",
    "            data,\n",
    "            params.get('n_clusters', 3),\n",
    "            params.get('distance_metric', 'euclidean'),\n",
    "            params.get('max_iter', 300)\n",
    "        )\n",
    "    elif selected_algorithm == \"K-Medoids\":\n",
    "        result = kmedoids_clustering(\n",
    "            data,\n",
    "            params.get('n_clusters', 3),\n",
    "            params.get('distance_metric', 'euclidean'),\n",
    "            params.get('max_iter', 300)\n",
    "        )\n",
    "    else:\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(tk.END, \"Unsupported algorithm selected\")\n",
    "        return\n",
    "\n",
    "    clustering_results = result\n",
    "\n",
    "    if 'error' not in result:\n",
    "        plot_scatter_clusters(result)\n",
    "        nextStepVisualization.config(state=tk.NORMAL)\n",
    "        nextStepVisualization.config(bg=\"#24367E\")\n",
    "\n",
    "    update_results_display(result)\n",
    "\n",
    "# 3- 2)density algorithms\n",
    "def apply_density_algorithm():\n",
    "    global clustering_results, selected_algorithm, current_algorithm_type\n",
    "\n",
    "    if not selected_algorithm or current_algorithm_type != \"Density-based\":\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(\n",
    "            tk.END, \"Please select a density-based algorithm first\")\n",
    "        return\n",
    "\n",
    "    data, error = prepare_data_for_clustering()\n",
    "    if error:\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(tk.END, f\"Data preparation error: {error}\")\n",
    "        return\n",
    "\n",
    "    params = get_parameter_values()\n",
    "\n",
    "    if selected_algorithm == \"DBSCAN\":\n",
    "        result = dbscan_clustering(\n",
    "            data,\n",
    "            params.get('eps', 0.5),\n",
    "            params.get('min_samples', 5)\n",
    "        )\n",
    "    else:\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(tk.END, \"Unsupported algorithm selected\")\n",
    "        return\n",
    "\n",
    "    clustering_results = result\n",
    "\n",
    "    if 'error' not in result:\n",
    "        plot_dbscan_clusters(result)\n",
    "        nextStepVisualization.config(state=tk.NORMAL)\n",
    "        nextStepVisualization.config(bg=\"#24367E\")\n",
    "\n",
    "    update_results_display(result)\n",
    "\n",
    "# 3 - 3)hierarchical algorithms\n",
    "def apply_hierarchical_algorithm():\n",
    "    global clustering_results, selected_algorithm, current_algorithm_type\n",
    "\n",
    "    if not selected_algorithm or current_algorithm_type != \"Hierarchical\":\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(\n",
    "            tk.END, \"Please select a hierarchical algorithm first\")\n",
    "        return\n",
    "\n",
    "    # prepare data\n",
    "    data, error = prepare_data_for_clustering()\n",
    "    if error:\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(tk.END, f\"Data preparation error: {error}\")\n",
    "        return\n",
    "\n",
    "    # get parameters from UI\n",
    "    params = get_parameter_values()\n",
    "\n",
    "    # apply appropriate algorithm\n",
    "    if selected_algorithm == \"AGNES\":\n",
    "        result = agnes_clustering(\n",
    "            data,\n",
    "            params.get('n_clusters', 3),\n",
    "            params.get('linkage', 'single'),\n",
    "            params.get('distance_metric', 'euclidean')\n",
    "        )\n",
    "    elif selected_algorithm == \"DIANA\":\n",
    "        result = diana_clustering(\n",
    "            data,\n",
    "            params.get('n_clusters', 3),\n",
    "            params.get('distance_metric', 'euclidean')\n",
    "        )\n",
    "    else:\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(tk.END, \"Unsupported algorithm selected\")\n",
    "        return\n",
    "\n",
    "    # store results globally\n",
    "    clustering_results = result\n",
    "\n",
    "    # update visualization and results\n",
    "    if 'error' not in result:\n",
    "        plot_dendrogram(result)\n",
    "\n",
    "        # enable next step button\n",
    "        nextStepVisualization.config(state=tk.NORMAL)\n",
    "        nextStepVisualization.config(bg=\"#24367E\")\n",
    "\n",
    "    update_results_display(result)\n",
    "\n",
    "# min function to apply selected algorithm\n",
    "def apply_selected_algorithm():\n",
    "    # depend on current algorithm type, call appropriate function\n",
    "    if current_algorithm_type == \"Hierarchical\":\n",
    "        apply_hierarchical_algorithm()\n",
    "    elif current_algorithm_type == \"Partitioning\":\n",
    "        apply_partitioning_algorithm()\n",
    "    elif current_algorithm_type == \"Density-based\":\n",
    "        apply_density_algorithm()\n",
    "    else:\n",
    "        resultsTextArea.delete(1.0, tk.END)\n",
    "        resultsTextArea.insert(tk.END, \"Algorithm implementation pending...\")\n",
    "\n",
    "\n",
    "# assign main function to the apply button\n",
    "applyAlgorithmBtn.config(command=apply_selected_algorithm)\n",
    "\n",
    "# next step button action\n",
    "nextStepVisualization.config(command=incrementStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911c107",
   "metadata": {},
   "source": [
    "#### 1 - g  Comparaison Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97d738",
   "metadata": {},
   "source": [
    "##### 1 - g comparaison frame design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d70c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison frame design\n",
    "comparaisonFrame = tk.Frame(window, bg=\"#f0f0f0\")\n",
    "\n",
    "comparisonTitleLabel = tk.Label(comparaisonFrame, text=\"Algorithm Comparison Interface\",\n",
    "                                bg=\"#f0f0f0\", fg=\"#24367E\", font=(\"Arial\", 13, \"bold\"))\n",
    "comparisonTitleLabel.pack(pady=2)\n",
    "\n",
    "# main container frame\n",
    "mainComparisonFrame = tk.Frame(comparaisonFrame, bg=\"#f0f0f0\")\n",
    "mainComparisonFrame.pack(fill=tk.BOTH, expand=True, padx=10, pady=2)\n",
    "\n",
    "# grid configuration\n",
    "mainComparisonFrame.grid_columnconfigure(0, weight=1)\n",
    "mainComparisonFrame.grid_columnconfigure(1, weight=1)\n",
    "mainComparisonFrame.grid_rowconfigure(0, weight=1)\n",
    "\n",
    "# left section - same type comparison\n",
    "leftSection = tk.Frame(mainComparisonFrame, bd=2)\n",
    "leftSection.grid(row=0, column=0, sticky=\"nsew\", padx=(0, 3))\n",
    "\n",
    "# left metrics table frame\n",
    "leftMetricsFrame = tk.Frame(leftSection, bg=\"white\", relief=\"sunken\", bd=2)\n",
    "leftMetricsFrame.pack(fill=tk.X, padx=10, pady=5)\n",
    "\n",
    "leftMetricsTitle = tk.Label(leftMetricsFrame, text=\"Silhouette Score Comparison\",\n",
    "                            bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 10, \"bold\"))\n",
    "leftMetricsTitle.pack(pady=2)\n",
    "\n",
    "# left treeview (table) for metrics\n",
    "leftTreeview = ttk.Treeview(leftMetricsFrame, columns=(\n",
    "    'My Algorithm', 'Algorithm2'), height=1, show='headings')\n",
    "leftTreeview.pack(fill=tk.X, padx=10, pady=5)\n",
    "\n",
    "leftTreeview.heading('My Algorithm', text='My Algorithm')\n",
    "leftTreeview.heading('Algorithm2', text='Algorithm 2')\n",
    "leftTreeview.column('My Algorithm', width=120)\n",
    "leftTreeview.column('Algorithm2', width=120)\n",
    "\n",
    "# left plots frame\n",
    "leftPlotsFrame = tk.Frame(leftSection, bg=\"white\", relief=\"sunken\", bd=2)\n",
    "leftPlotsFrame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)\n",
    "\n",
    "leftPlotsTitle = tk.Label(leftPlotsFrame, text=\"Visual Comparison\",\n",
    "                          bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 10, \"bold\"))\n",
    "leftPlotsTitle.pack(pady=3)\n",
    "\n",
    "# left plot area \n",
    "leftSinglePlotFrame = tk.Frame(leftPlotsFrame, bg=\"white\", relief=\"groove\", bd=1)\n",
    "leftSinglePlotFrame.pack(fill=tk.BOTH, expand=True, padx=5, pady=2)\n",
    "\n",
    "leftSinglePlotCanvas = tk.Frame(leftSinglePlotFrame, bg=\"white\")\n",
    "leftSinglePlotCanvas.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# right section - all algorithms comparison\n",
    "rightSection = tk.Frame(mainComparisonFrame, bd=2)\n",
    "rightSection.grid(row=0, column=1, sticky=\"nsew\", padx=(5, 0))\n",
    "\n",
    "rightTitleLabel = tk.Label(rightSection, text=\"All Algorithms Comparison\",\n",
    "                           bg=\"#f8f9fa\", fg=\"#24367E\", font=(\"Arial\", 11, \"bold\"))\n",
    "rightTitleLabel.pack(pady=3)\n",
    "\n",
    "# right metrics table frame\n",
    "rightMetricsFrame = tk.Frame(rightSection, bg=\"white\", relief=\"sunken\", bd=2)\n",
    "rightMetricsFrame.pack(fill=tk.X, padx=10, pady=3)\n",
    "\n",
    "rightMetricsTitle = tk.Label(rightMetricsFrame, text=\"Silhouette Score Comparison\",\n",
    "                             bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 10, \"bold\"))\n",
    "rightMetricsTitle.pack(pady=2)\n",
    "\n",
    "# right treeview (table) for metrics\n",
    "rightTreeview = ttk.Treeview(rightMetricsFrame, columns=(\n",
    "    'MyGlobalAlgorithm', 'algorithm2', 'algorithm3', 'algorithm4'), height=1, show='headings')\n",
    "rightTreeview.pack(fill=tk.X, padx=10, pady=5)\n",
    "\n",
    "rightTreeview.heading('MyGlobalAlgorithm', text='My Algorithm')\n",
    "rightTreeview.heading('algorithm2', text='Algorithm 2')\n",
    "rightTreeview.heading('algorithm3', text='Algorithm 3')\n",
    "rightTreeview.heading('algorithm4', text='Algorithm 4')\n",
    "rightTreeview.column('MyGlobalAlgorithm', width=80)\n",
    "rightTreeview.column('algorithm2', width=80)\n",
    "rightTreeview.column('algorithm3', width=80)\n",
    "rightTreeview.column('algorithm4', width=80)\n",
    "\n",
    "# right plots frame\n",
    "rightPlotsFrame = tk.Frame(rightSection, bg=\"white\", relief=\"sunken\", bd=2)\n",
    "rightPlotsFrame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)\n",
    "\n",
    "rightPlotsTitle = tk.Label(rightPlotsFrame, text=\"All Algorithms Visualization\",\n",
    "                           bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 10, \"bold\"))\n",
    "rightPlotsTitle.pack(pady=2)\n",
    "\n",
    "# right plots grid\n",
    "rightPlotsGrid = tk.Frame(rightPlotsFrame, bg=\"white\")\n",
    "rightPlotsGrid.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "\n",
    "rightPlotsGrid.grid_columnconfigure(0, weight=1)\n",
    "rightPlotsGrid.grid_columnconfigure(1, weight=1)\n",
    "rightPlotsGrid.grid_rowconfigure(0, weight=1)\n",
    "rightPlotsGrid.grid_rowconfigure(1, weight=1)\n",
    "\n",
    "# first row plots\n",
    "rightPlot1Frame = tk.Frame(rightPlotsGrid, bg=\"white\", relief=\"groove\", bd=1)\n",
    "rightPlot1Frame.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "rightPlot1Label = tk.Label(rightPlot1Frame, text=\"Algorithm 1\",\n",
    "                           bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 9, \"bold\"))\n",
    "rightPlot1Label.pack()\n",
    "\n",
    "rightPlot1Canvas = tk.Frame(rightPlot1Frame, bg=\"white\", height=80)\n",
    "rightPlot1Canvas.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "rightPlot2Frame = tk.Frame(rightPlotsGrid, bg=\"white\", relief=\"groove\", bd=1)\n",
    "rightPlot2Frame.grid(row=0, column=1, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "rightPlot2Label = tk.Label(rightPlot2Frame, text=\"Algorithm 2\",\n",
    "                           bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 9, \"bold\"))\n",
    "rightPlot2Label.pack()\n",
    "\n",
    "rightPlot2Canvas = tk.Frame(rightPlot2Frame, bg=\"white\", height=80)\n",
    "rightPlot2Canvas.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# second row plots\n",
    "rightPlot3Frame = tk.Frame(rightPlotsGrid, bg=\"white\", relief=\"groove\", bd=1)\n",
    "rightPlot3Frame.grid(row=1, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "rightPlot3Label = tk.Label(rightPlot3Frame, text=\"Algorithm 3\",\n",
    "                           bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 9, \"bold\"))\n",
    "rightPlot3Label.pack()\n",
    "\n",
    "rightPlot3Canvas = tk.Frame(rightPlot3Frame, bg=\"white\", height=80)\n",
    "rightPlot3Canvas.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "rightPlot4Frame = tk.Frame(rightPlotsGrid, bg=\"white\", relief=\"groove\", bd=1)\n",
    "rightPlot4Frame.grid(row=1, column=1, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "rightPlot4Label = tk.Label(rightPlot4Frame, text=\"Algorithm 4\",\n",
    "                           bg=\"white\", fg=\"#24367E\", font=(\"Arial\", 9, \"bold\"))\n",
    "rightPlot4Label.pack()\n",
    "\n",
    "rightPlot4Canvas = tk.Frame(rightPlot4Frame, bg=\"white\", height=80)\n",
    "rightPlot4Canvas.pack(fill=tk.BOTH, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d17c9",
   "metadata": {},
   "source": [
    "#### 1 - g comparaison frame logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52402f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables for comparison\n",
    "comparison_algorithms = ['K-Means', 'K-Medoids', 'AGNES', 'DIANA', 'DBSCAN']\n",
    "comparison_results = {}\n",
    "\n",
    "# calculate silhouette scores for all algorithms\n",
    "def calculate_silhouette_scores():\n",
    "    global comparison_results, optimal_k_global , params\n",
    "\n",
    "    data, error = prepare_data_for_clustering()\n",
    "    if data is None or error:\n",
    "        return None\n",
    "    \n",
    "    comparison_results = {}\n",
    "    \n",
    "    # get parameters from UI\n",
    "    k_clusters = optimal_k_global if optimal_k_global else 3\n",
    "    distance_metric = params['distance_metric'] if 'distance_metric' in params else 'euclidean'\n",
    "    linkage_method = params['linkage'] if 'linkage' in params else 'single'\n",
    "    n_iterations = params['max_iter'] if 'max_iter' in params else 300\n",
    "    eps = params['eps'] if 'eps' in params else 0.5\n",
    "    min_samples = params['min_samples'] if 'min_samples' in params else 5\n",
    "\n",
    "    # calculate silhouette scores for each algorithm\n",
    "    for algo in comparison_algorithms:\n",
    "        try:\n",
    "            if algo == 'K-Means':\n",
    "                result = kmeans_clustering(data, k_clusters, distance_metric, n_iterations)\n",
    "            elif algo == 'K-Medoids':\n",
    "                result = kmedoids_clustering(data, k_clusters, distance_metric, n_iterations)\n",
    "            elif algo == 'AGNES':\n",
    "                result = agnes_clustering(data, k_clusters, linkage_method, distance_metric)\n",
    "            elif algo == 'DIANA':\n",
    "                result = diana_clustering(data, k_clusters, distance_metric)\n",
    "            elif algo == 'DBSCAN':\n",
    "                result = dbscan_clustering(data, eps, min_samples)\n",
    "            \n",
    "            if 'error' not in result:\n",
    "                if algo == 'DBSCAN' and result['n_clusters'] < 2:\n",
    "                    comparison_results[algo] = {'silhouette': None, 'result': result}\n",
    "                else:\n",
    "                    sil_score = silhouette_score(data, result['labels'])\n",
    "                    comparison_results[algo] = {'silhouette': sil_score, 'result': result}\n",
    "            else:\n",
    "                comparison_results[algo] = {'silhouette': None, 'result': None}\n",
    "                \n",
    "        except Exception as e:\n",
    "            comparison_results[algo] = {'silhouette': None, 'result': None}\n",
    "    \n",
    "    return comparison_results\n",
    "\n",
    "# get algorithms of the same type as the selected one\n",
    "def get_same_type_algorithms():\n",
    "    if current_algorithm_type == \"Partitioning\":\n",
    "        return ['K-Means', 'K-Medoids']\n",
    "    elif current_algorithm_type == \"Hierarchical\":\n",
    "        return ['AGNES', 'DIANA']\n",
    "    else:\n",
    "        return ['DBSCAN']\n",
    "\n",
    "\n",
    "# update comparison tables in GUI\n",
    "def update_comparison_tables():\n",
    "    global selected_algorithm\n",
    "    \n",
    "    if not selected_algorithm:\n",
    "        return\n",
    "    \n",
    "    scores = calculate_silhouette_scores()\n",
    "    if not scores:\n",
    "        return\n",
    "    \n",
    "    same_type_algos = get_same_type_algorithms()\n",
    "    leftTreeview.delete(*leftTreeview.get_children())\n",
    "    \n",
    "    if selected_algorithm != 'DBSCAN' and len(same_type_algos) > 1:\n",
    "        other_algo = [a for a in same_type_algos if a != selected_algorithm][0]\n",
    "        \n",
    "        leftTreeview.heading('#1', text=selected_algorithm)\n",
    "        leftTreeview.heading('#2', text=other_algo)\n",
    "        \n",
    "        my_score = scores.get(selected_algorithm, {}).get('silhouette', None)\n",
    "        other_score = scores.get(other_algo, {}).get('silhouette', None)\n",
    "        \n",
    "        \n",
    "        my_score_str = f\"{my_score:.3f}\" if (my_score is not None and isinstance(my_score, (int, float))) else 'N/A'\n",
    "        other_score_str = f\"{other_score:.3f}\" if (other_score is not None and isinstance(other_score, (int, float))) else 'N/A'\n",
    "        \n",
    "        item = leftTreeview.insert('', 'end', values=(my_score_str, other_score_str))\n",
    "        leftTreeview.item(item, tags=('selected',))\n",
    "    \n",
    "    rightTreeview.delete(*rightTreeview.get_children())\n",
    "    \n",
    "    other_algos = [a for a in comparison_algorithms if a != selected_algorithm][:3]\n",
    "    \n",
    "    rightTreeview.heading('#1', text=selected_algorithm)\n",
    "    \n",
    "    for i, algo in enumerate(other_algos):\n",
    "        if i < 3:\n",
    "            rightTreeview.heading(f'#{i+2}', text=algo)\n",
    "    \n",
    "    for i in range(len(other_algos) + 1, 4):\n",
    "        if i < 4:\n",
    "            rightTreeview.heading(f'#{i+1}', text='')\n",
    "    \n",
    "    values = []\n",
    "    my_score = scores.get(selected_algorithm, {}).get('silhouette', None)\n",
    "    values.append(f\"{my_score:.3f}\" if (my_score is not None and isinstance(my_score, (int, float)) and -1 <= my_score <= 1) else 'N/A')\n",
    "    \n",
    "    for algo in other_algos:\n",
    "        score = scores.get(algo, {}).get('silhouette', None)\n",
    "        values.append(f\"{score:.3f}\" if (score is not None and isinstance(score, (int, float)) and -1 <= score <= 1) else 'N/A')\n",
    "    \n",
    "    while len(values) < 4:\n",
    "        values.append('')\n",
    "    values = values[:4]\n",
    "    \n",
    "    item = rightTreeview.insert('', 'end', values=values)\n",
    "    rightTreeview.item(item, tags=('selected',))\n",
    "\n",
    "\n",
    "# plot comparison visualization\n",
    "def plot_algorithm_comparison(algorithm_name, canvas_frame, size=(2, 1)):\n",
    "    for widget in canvas_frame.winfo_children():\n",
    "        widget.destroy()\n",
    "    \n",
    "    if algorithm_name not in comparison_results or not comparison_results[algorithm_name]['result']:\n",
    "        placeholder = tk.Label(canvas_frame, text=f\"{algorithm_name}\\nNo Data\", \n",
    "                              bg=\"white\", fg=\"#666\", font=(\"Arial\", 8))\n",
    "        placeholder.pack(expand=True)\n",
    "        return\n",
    "    \n",
    "    result = comparison_results[algorithm_name]['result']\n",
    "    data, _ = prepare_data_for_clustering()\n",
    "    \n",
    "    if data is None:\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=size)\n",
    "    \n",
    "    if algorithm_name in ['AGNES', 'DIANA']:\n",
    "        # plot dendrogram for hierarchical algorithms\n",
    "        try:\n",
    "            dend = dendrogram(result['linkage_matrix'], ax=ax,\n",
    "                              truncate_mode='lastp', p=10,\n",
    "                              show_leaf_counts=False)\n",
    "            ax.set_xlabel('')\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_title(algorithm_name, fontsize=8)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"{algorithm_name}\\nDendrogram Error\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "    else:\n",
    "        # use first two dimensions for visualization (only first two numeric columns)\n",
    "        if data.shape[1] >= 2:\n",
    "            x_data = data[:, 0]\n",
    "            y_data = data[:, 1]\n",
    "        else:\n",
    "            x_data = data[:, 0]\n",
    "            y_data = np.zeros(len(data))\n",
    "        \n",
    "        if algorithm_name == 'DBSCAN':\n",
    "            # dbscan specific plotting\n",
    "            labels = result['labels']\n",
    "            unique_labels = set(labels)\n",
    "            colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "            \n",
    "            for k, col in zip(unique_labels, colors):\n",
    "                if k == -1:\n",
    "                    col = [0, 0, 0, 1]\n",
    "                class_member_mask = (labels == k)\n",
    "                xy = np.column_stack([x_data[class_member_mask], y_data[class_member_mask]])\n",
    "                if len(xy) > 0:\n",
    "                    ax.scatter(xy[:, 0], xy[:, 1], c=[col], s=20, alpha=0.7)\n",
    "        else:\n",
    "            # scatter plot for partitioning algorithms\n",
    "            scatter = ax.scatter(x_data, y_data, c=result['labels'], cmap='viridis', s=20, alpha=0.7)\n",
    "            \n",
    "            if 'centers' in result:\n",
    "                centers = result['centers']\n",
    "                if centers.shape[1] >= 2:\n",
    "                    ax.scatter(centers[:, 0], centers[:, 1], c='red', marker='x', s=100, linewidths=2)\n",
    "                else:\n",
    "                    ax.scatter(centers[:, 0], np.zeros(len(centers)), c='red', marker='x', s=100, linewidths=2)\n",
    "            elif 'medoids' in result:\n",
    "                medoids = result['medoids']\n",
    "                if medoids.shape[1] >= 2:\n",
    "                    ax.scatter(medoids[:, 0], medoids[:, 1], c='red', marker='s', s=100, linewidths=2)\n",
    "                else:\n",
    "                    ax.scatter(medoids[:, 0], np.zeros(len(medoids)), c='red', marker='s', s=100, linewidths=2)\n",
    "        \n",
    "        ax.set_title(algorithm_name, fontsize=8)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, canvas_frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# plot inertia comparison for partitioning algorithms\n",
    "def plot_partitioning_inertia_comparison():\n",
    "    for widget in leftSinglePlotCanvas.winfo_children():\n",
    "        widget.destroy()\n",
    "    \n",
    "    # get inertia values from comparison results\n",
    "    kmeans_inertia = None\n",
    "    kmedoids_inertia = None\n",
    "    \n",
    "    if 'K-Means' in comparison_results and comparison_results['K-Means']['result']:\n",
    "        kmeans_result = comparison_results['K-Means']['result']\n",
    "        if 'inertia' in kmeans_result:\n",
    "            kmeans_inertia = kmeans_result['inertia']\n",
    "    \n",
    "    if 'K-Medoids' in comparison_results and comparison_results['K-Medoids']['result']:\n",
    "        kmedoids_result = comparison_results['K-Medoids']['result']\n",
    "        if 'inertia' in kmedoids_result:\n",
    "            kmedoids_inertia = kmedoids_result['inertia']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4, 2))\n",
    "    \n",
    "    algorithms = []\n",
    "    inertias = []\n",
    "    colors = []\n",
    "    \n",
    "    if kmeans_inertia is not None:\n",
    "        algorithms.append('K-Means')\n",
    "        inertias.append(kmeans_inertia)\n",
    "        colors.append('#1f77b4' if selected_algorithm == 'K-Means' else '#aec7e8')\n",
    "    \n",
    "    if kmedoids_inertia is not None:\n",
    "        algorithms.append('K-Medoids')\n",
    "        inertias.append(kmedoids_inertia)\n",
    "        colors.append('#ff7f0e' if selected_algorithm == 'K-Medoids' else '#ffbb78')\n",
    "    \n",
    "    if len(algorithms) > 0:\n",
    "        bars = ax.bar(algorithms, inertias, color=colors, alpha=0.8, edgecolor='black')\n",
    "        \n",
    "        for bar, inertia in zip(bars, inertias):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{inertia:.2f}',\n",
    "                   ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        if selected_algorithm in algorithms:\n",
    "            selected_idx = algorithms.index(selected_algorithm)\n",
    "            bars[selected_idx].set_edgecolor('red')\n",
    "            bars[selected_idx].set_linewidth(3)\n",
    "        \n",
    "        ax.set_title('Inertia Comparison', fontsize=11, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, leftSinglePlotCanvas)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# plot dendrogram comparison for hierarchical algorithms\n",
    "def plot_hierarchical_dendrograms_comparison():\n",
    "    for widget in leftSinglePlotCanvas.winfo_children():\n",
    "        widget.destroy()\n",
    "    \n",
    "    agnes_result = comparison_results.get('AGNES', {}).get('result')\n",
    "    diana_result = comparison_results.get('DIANA', {}).get('result')\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    \n",
    "    # plot agnes dendrogram\n",
    "    if agnes_result and 'linkage_matrix' in agnes_result:\n",
    "        try:\n",
    "            dend1 = dendrogram(agnes_result['linkage_matrix'], ax=ax1,\n",
    "                              truncate_mode='lastp', p=15,\n",
    "                              show_leaf_counts=False)\n",
    "            ax1.set_title('AGNES', fontsize=10, fontweight='bold')\n",
    "            \n",
    "            # highlight selected algorithm\n",
    "            if selected_algorithm == 'AGNES':\n",
    "                ax1.set_facecolor('#ffe6e6')\n",
    "                for spine in ax1.spines.values():\n",
    "                    spine.set_edgecolor('red')\n",
    "                    spine.set_linewidth(2)\n",
    "        except Exception as e:\n",
    "            ax1.text(0.5, 0.5, 'AGNES\\nDendrogram Error', \n",
    "                    ha='center', va='center', transform=ax1.transAxes, fontsize=10)\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'AGNES\\nNo Data', \n",
    "                ha='center', va='center', transform=ax1.transAxes, fontsize=10)\n",
    "    \n",
    "    # plot diana dendrogram\n",
    "    if diana_result and 'linkage_matrix' in diana_result:\n",
    "        try:\n",
    "            dend2 = dendrogram(diana_result['linkage_matrix'], ax=ax2,\n",
    "                              truncate_mode='lastp', p=15,\n",
    "                              show_leaf_counts=False)\n",
    "            ax2.set_title('DIANA', fontsize=10, fontweight='bold')\n",
    "            \n",
    "            if selected_algorithm == 'DIANA':\n",
    "                ax2.set_facecolor('#ffe6e6')\n",
    "                for spine in ax2.spines.values():\n",
    "                    spine.set_edgecolor('red')\n",
    "                    spine.set_linewidth(2)\n",
    "        except Exception as e:\n",
    "            ax2.text(0.5, 0.5, 'DIANA\\nDendrogram Error', \n",
    "                    ha='center', va='center', transform=ax2.transAxes, fontsize=10)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'DIANA\\nNo Data', \n",
    "                ha='center', va='center', transform=ax2.transAxes, fontsize=10)\n",
    "    \n",
    "    fig.suptitle('Hierarchical Algorithms Comparison', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, leftSinglePlotCanvas)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# plot dbscan visualization\n",
    "def plot_dbscan_single():\n",
    "    for widget in leftSinglePlotCanvas.winfo_children():\n",
    "        widget.destroy()\n",
    "    \n",
    "    dbscan_result = comparison_results.get('DBSCAN', {}).get('result')\n",
    "    \n",
    "    if not dbscan_result:\n",
    "        placeholder = tk.Label(leftSinglePlotCanvas, text=\"DBSCAN\\nNo Data Available\", \n",
    "                              bg=\"white\", fg=\"#666\", font=(\"Arial\", 12))\n",
    "        placeholder.pack(expand=True)\n",
    "        return\n",
    "    \n",
    "    data, _ = prepare_data_for_clustering()\n",
    "    if data is None:\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    \n",
    "    # use first two dimensions for visualization (first two numeric columns)\n",
    "    if data.shape[1] >= 2:\n",
    "        x_data = data[:, 0]\n",
    "        y_data = data[:, 1]\n",
    "    else:\n",
    "        x_data = data[:, 0]\n",
    "        y_data = np.zeros(len(data))\n",
    "    \n",
    "    labels = dbscan_result['labels']\n",
    "    core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
    "    core_samples_mask[dbscan_result['core_sample_indices']] = True\n",
    "    \n",
    "    unique_labels = set(labels)\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            col = [0, 0, 0, 1]\n",
    "        \n",
    "        class_member_mask = (labels == k)\n",
    "        \n",
    "        # plot core samples\n",
    "        xy_core = np.column_stack([x_data[class_member_mask & core_samples_mask],\n",
    "                                   y_data[class_member_mask & core_samples_mask]])\n",
    "        if len(xy_core) > 0:\n",
    "            if k == -1:\n",
    "                ax.scatter(xy_core[:, 0], xy_core[:, 1], s=50, c=[col], marker='x',\n",
    "                          alpha=0.8, label='Noise' if k == -1 else f'Core {k}')\n",
    "            else:\n",
    "                ax.scatter(xy_core[:, 0], xy_core[:, 1], s=80, c=[col], marker='o',\n",
    "                          edgecolors='black', linewidths=1, alpha=0.8)\n",
    "        \n",
    "        # plot border samples\n",
    "        xy_border = np.column_stack([x_data[class_member_mask & ~core_samples_mask],\n",
    "                                     y_data[class_member_mask & ~core_samples_mask]])\n",
    "        if len(xy_border) > 0 and k != -1:\n",
    "            ax.scatter(xy_border[:, 0], xy_border[:, 1], s=40, c=[col], marker='o',\n",
    "                      alpha=0.6, edgecolors='black', linewidths=0.5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_title(f'DBSCAN Clustering (eps={dbscan_result[\"eps\"]}, min_samples={dbscan_result[\"min_samples\"]})', \n",
    "                fontsize=8, fontweight='bold')\n",
    "    \n",
    "    n_clusters = dbscan_result['n_clusters']\n",
    "    n_noise = dbscan_result['n_noise_points']\n",
    "    ax.text(0.02, 0.98, f'Clusters: {n_clusters}\\nNoise Points: {n_noise}', \n",
    "           transform=ax.transAxes, fontsize=10, fontweight='bold',\n",
    "           verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, leftSinglePlotCanvas)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# update left single plot based on selected algorithm type\n",
    "def update_left_single_plot():\n",
    "    if not selected_algorithm:\n",
    "        return\n",
    "\n",
    "    \n",
    "    if current_algorithm_type == \"Partitioning\":\n",
    "        # show inertia histogram for partitioning algorithms\n",
    "        plot_partitioning_inertia_comparison()\n",
    "    elif current_algorithm_type == \"Hierarchical\":\n",
    "        # show side by side dendrograms for hierarchical algorithms\n",
    "        plot_hierarchical_dendrograms_comparison()\n",
    "    elif current_algorithm_type == \"Density-based\":\n",
    "        # show dbscan visualization only\n",
    "        plot_dbscan_single()\n",
    "    else:\n",
    "        for widget in leftSinglePlotCanvas.winfo_children():\n",
    "            widget.destroy()\n",
    "        placeholder = tk.Label(leftSinglePlotCanvas, text=\"No Algorithm Selected\", \n",
    "                              bg=\"white\", fg=\"#666\", font=(\"Arial\", 12))\n",
    "        placeholder.pack(expand=True)\n",
    "\n",
    "# update right plots for all algorithms comparison\n",
    "def update_right_plots():\n",
    "    if not selected_algorithm:\n",
    "        return\n",
    "    \n",
    "    other_algos = [a for a in comparison_algorithms if a != selected_algorithm]\n",
    "    plot_frames = [rightPlot1Canvas, rightPlot2Canvas, rightPlot3Canvas, rightPlot4Canvas]\n",
    "    plot_labels = [rightPlot1Label, rightPlot2Label, rightPlot3Label, rightPlot4Label]\n",
    "    \n",
    "    for i, (algo, frame, label) in enumerate(zip(other_algos, plot_frames, plot_labels)):\n",
    "        label.config(text=algo)\n",
    "        plot_algorithm_comparison(algo, frame, (2.5, 1.5))\n",
    "\n",
    "# main function to run comparison analysis\n",
    "def run_comparison_analysis():\n",
    "    if not selected_algorithm:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # calculate all scores and results\n",
    "        calculate_silhouette_scores()\n",
    "        \n",
    "        # update tables\n",
    "        update_comparison_tables()\n",
    "        \n",
    "        # update left single plot based on algorithm type\n",
    "        update_left_single_plot()\n",
    "        \n",
    "        # update right plots (unchanged)\n",
    "        update_right_plots()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in comparison analysis: {e}\")\n",
    "\n",
    "# automatic run comparison after comparison frame is shown\n",
    "def auto_run_comparison():\n",
    "    window.after(100, run_comparison_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67547ed7",
   "metadata": {},
   "source": [
    "### 2 - show the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "650bf931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage du GUI\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
